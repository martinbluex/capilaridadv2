{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f47065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:121: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:121: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\martin.olivares\\AppData\\Local\\Temp\\ipykernel_28492\\2314124282.py:121: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  unified_path = 'Cartografia_censo2024_Pais\\Censo2024_Unificado_Nacional.parquet'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paso 1: Descargando Puntos Blue ---\n",
      "PostgreSQL no disponible (psycopg2 no instalado).\n",
      "Intentando cargar desde CSV: data/dummy_data.csv ...\n",
      "Datos cargados desde CSV: 3424 registros.\n",
      "GeoDataFrame creado: 3424 puntos.\n",
      "--- Paso 2: Cargando Censo 2024 (Urbano y Rural) ---\n",
      "Convirtiendo WKB...\n",
      "--- Cargando parquet unificado: Cartografia_censo2024_Pais\\Censo2024_Unificado_Nacional.parquet ---\n",
      "Convirtiendo WKB del parquet unificado...\n",
      "Rural agregado desde parquet unificado: 28,415 filas\n",
      "Censo cargado: urbano+rural 244,756 registros\n",
      "--- Paso 3: Preparando Datos (Nivel Manzana/Localidad) ---\n",
      "Proyectando a UTM 19S...\n",
      "--- Paso 4: Calculando Cobertura por Manzana/Localidad ---\n",
      "Procesando Comuna 20/345: CALBUCO\n",
      "Procesando Comuna 40/345: CHEPICA\n",
      "Procesando Comuna 60/345: COLTAUCO\n",
      "Procesando Comuna 80/345: DALCAHUE\n",
      "Procesando Comuna 100/345: GORBEA\n",
      "Procesando Comuna 120/345: LA FLORIDA\n",
      "Procesando Comuna 140/345: LINARES\n",
      "Procesando Comuna 160/345: MACHALI\n",
      "Procesando Comuna 180/345: NATALES\n",
      "Procesando Comuna 200/345: PALMILLA\n",
      "Procesando Comuna 220/345: PICHILEMU\n",
      "Procesando Comuna 240/345: PUQUELDON\n",
      "Procesando Comuna 260/345: RANCAGUA\n",
      "Procesando Comuna 280/345: SAN ANTONIO\n",
      "Procesando Comuna 300/345: SAN RAFAEL\n",
      "Procesando Comuna 320/345: TIMAUKEL\n",
      "Procesando Comuna 340/345: VINA DEL MAR\n",
      "--- Paso 5: Guardando Reporte Granular ---\n",
      "Generando Excel con 244756 filas...\n",
      "Archivo generado: Cobertura_Censo24_Por_Manzana.xlsx\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import psycopg2\n",
    "    HAS_POSTGRES = False #para forzar uso de dummy data\n",
    "except ImportError:\n",
    "    HAS_POSTGRES = False\n",
    "    print(\"psycopg2 no instalado. Se usará modo offline (CSV).\")\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import unicodedata\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from shapely import wkb\n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 0. FUNCIONES\n",
    "# ==========================================\n",
    "\n",
    "def safe_read_parquet(path):\n",
    "    \"\"\"Lee archivos parquet con manejo robusto.\"\"\"\n",
    "    try:\n",
    "        return pd.read_parquet(path, engine='pyarrow')\n",
    "    except Exception as e:\n",
    "        print(f\"Error PyArrow: {e}. Intentando fastparquet...\")\n",
    "        return pd.read_parquet(path, engine='fastparquet')\n",
    "\n",
    "def normalize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip().upper()\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    return text\n",
    "\n",
    "# ==========================================\n",
    "# 1. CARGA DE PUNTOS BLUE (SQL o CSV)\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 1: Descargando Puntos Blue ---\")\n",
    "\n",
    "DB_HOST = \"dwh.datarq.blue.internal\"\n",
    "DB_NAME = \"dwh\"\n",
    "DB_USER = \"molivares\" \n",
    "DB_PASS = \"MA2012\"\n",
    "CSV_PATH = 'data/dummy_data.csv'\n",
    "\n",
    "PUDOS_Bx = None\n",
    "\n",
    "# Intentar cargar desde SQL\n",
    "if HAS_POSTGRES:\n",
    "    try:\n",
    "        print(\"Intentando conectar a PostgreSQL...\")\n",
    "        con = psycopg2.connect(database=DB_NAME, user=DB_USER, password=DB_PASS, host=DB_HOST, port=\"5432\")\n",
    "        cur = con.cursor()\n",
    "        sql = \"SELECT cmns_nmb, geol_latitud, geol_longitud, estado,esto_seq_cdg FROM reports.pickup_maestro_v02 WHERE estado = 'active';\"\n",
    "        cur.execute(sql)\n",
    "        rows = cur.fetchall()\n",
    "        columns = [desc[0] for desc in cur.description]\n",
    "        con.close()\n",
    "        \n",
    "        PUDOS_Bx = pd.DataFrame(rows, columns=columns)\n",
    "        print(f\"Datos cargados desde SQL: {len(PUDOS_Bx)} registros.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error SQL: {e}\")\n",
    "        PUDOS_Bx = None\n",
    "else:\n",
    "    print(\"PostgreSQL no disponible (psycopg2 no instalado).\")\n",
    "\n",
    "# Si falló SQL o no hay driver, intentar CSV\n",
    "if PUDOS_Bx is None:\n",
    "    print(f\"Intentando cargar desde CSV: {CSV_PATH} ...\")\n",
    "    try:\n",
    "        PUDOS_Bx = pd.read_csv(CSV_PATH)\n",
    "        print(f\"Datos cargados desde CSV: {len(PUDOS_Bx)} registros.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando CSV: {e}\")\n",
    "        PUDOS_Bx = pd.DataFrame() # DataFrame vacío\n",
    "\n",
    "# Procesar si hay datos\n",
    "if not PUDOS_Bx.empty:\n",
    "    try:\n",
    "        # Limpieza coordenadas\n",
    "        if 'geol_latitud' in PUDOS_Bx.columns and 'geol_longitud' in PUDOS_Bx.columns:\n",
    "            PUDOS_Bx['geol_latitud'] = PUDOS_Bx['geol_latitud'].astype(str).str.replace(',', '.').astype(float)\n",
    "            PUDOS_Bx['geol_longitud'] = PUDOS_Bx['geol_longitud'].astype(str).str.replace(',', '.').astype(float)\n",
    "            \n",
    "            # Crear GeoDataFrame PUDO\n",
    "            gdf_PUDO = gpd.GeoDataFrame(PUDOS_Bx, geometry=gpd.points_from_xy(PUDOS_Bx.geol_longitud, PUDOS_Bx.geol_latitud), crs=\"EPSG:4326\")\n",
    "            \n",
    "            if 'cmns_nmb' in PUDOS_Bx.columns:\n",
    "                gdf_PUDO['COMUNA_NORM'] = gdf_PUDO['cmns_nmb'].apply(normalize_text)\n",
    "            else:\n",
    "                print(\"Advertencia: Columna 'cmns_nmb' no encontrada. Buscando alternativas...\")\n",
    "                if 'COMUNA' in PUDOS_Bx.columns:\n",
    "                     gdf_PUDO['COMUNA_NORM'] = PUDOS_Bx['COMUNA'].apply(normalize_text)\n",
    "                else:\n",
    "                     gdf_PUDO['COMUNA_NORM'] = ''\n",
    "            \n",
    "            print(f\"GeoDataFrame creado: {len(gdf_PUDO)} puntos.\")\n",
    "        else:\n",
    "             print(\"Error: El CSV no tiene columnas 'geol_latitud' y 'geol_longitud'.\")\n",
    "             gdf_PUDO = gpd.GeoDataFrame(columns=['cmns_nmb', 'geometry'], crs=\"EPSG:4326\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando datos: {e}\")\n",
    "        gdf_PUDO = gpd.GeoDataFrame(columns=['cmns_nmb', 'geometry'], crs=\"EPSG:4326\")\n",
    "else:\n",
    "    print(\"No se pudieron cargar datos (ni SQL ni CSV). Se usará GeoDataFrame vacío.\")\n",
    "    gdf_PUDO = gpd.GeoDataFrame(columns=['cmns_nmb', 'geometry'], crs=\"EPSG:4326\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. CARGA DE CENSO (URBANO + RURAL)\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 2: Cargando Censo 2024 (Urbano y Rural) ---\")\n",
    "\n",
    "path_manzanas = 'Cartografia_censo2024_Pais/Cartografia_censo2024_Pais_Manzanas.parquet'\n",
    "use_unified_parquet = True\n",
    "unified_path = 'Cartografia_censo2024_Pais\\Censo2024_Unificado_Nacional.parquet'\n",
    "rural_extra = gpd.GeoDataFrame(columns=['geometry'], crs='EPSG:4326')\n",
    "\n",
    "df_manzanas = safe_read_parquet(path_manzanas)\n",
    "\n",
    "# Geometría base\n",
    "col_geometria = 'geometry'\n",
    "if 'SHAPE' in df_manzanas.columns:\n",
    "    col_geometria = 'SHAPE'\n",
    "\n",
    "if df_manzanas[col_geometria].dtype == 'object' or isinstance(df_manzanas[col_geometria].iloc[0], bytes):\n",
    "    print(\"Convirtiendo WKB...\")\n",
    "    df_manzanas[col_geometria] = df_manzanas[col_geometria].apply(lambda x: wkb.loads(x) if isinstance(x, bytes) else x)\n",
    "\n",
    "manzanas_base = gpd.GeoDataFrame(df_manzanas, geometry=col_geometria)\n",
    "if manzanas_base.crs is None:\n",
    "    manzanas_base.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Población base\n",
    "if 'n_per' in manzanas_base.columns:\n",
    "    manzanas_base.rename(columns={'n_per': 'TOTAL_PERS'}, inplace=True)\n",
    "elif 'TOTAL_PERS' not in manzanas_base.columns:\n",
    "    manzanas_base['TOTAL_PERS'] = 0\n",
    "\n",
    "manzanas_base['TIPO_FUENTE'] = 'URBANO'\n",
    "frames_censo = [manzanas_base]\n",
    "\n",
    "if use_unified_parquet and Path(unified_path).exists():\n",
    "    print(f\"--- Cargando parquet unificado: {unified_path} ---\")\n",
    "    df_unif = safe_read_parquet(unified_path)\n",
    "\n",
    "    geom_col = None\n",
    "    if 'geometry' in df_unif.columns:\n",
    "        geom_col = 'geometry'\n",
    "    elif 'SHAPE' in df_unif.columns:\n",
    "        geom_col = 'SHAPE'\n",
    "    else:\n",
    "        for col in df_unif.columns:\n",
    "            if 'geom' in col.lower() or 'shape' in col.lower():\n",
    "                geom_col = col\n",
    "                break\n",
    "\n",
    "    if geom_col is None:\n",
    "        print(\"Advertencia: parquet unificado sin columna de geometría. Se mantiene manzanas base.\")\n",
    "    else:\n",
    "        if df_unif[geom_col].dtype == 'object' or isinstance(df_unif[geom_col].iloc[0], bytes):\n",
    "            print(\"Convirtiendo WKB del parquet unificado...\")\n",
    "            df_unif[geom_col] = df_unif[geom_col].apply(lambda x: wkb.loads(x) if isinstance(x, bytes) else x)\n",
    "\n",
    "        gdf_unif = gpd.GeoDataFrame(df_unif, geometry=geom_col)\n",
    "        if gdf_unif.crs is None:\n",
    "            gdf_unif.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "        gdf_unif['TIPO_REGISTRO'] = gdf_unif['TIPO_REGISTRO'].fillna('')\n",
    "        if 'TOTAL_PERS' not in gdf_unif.columns and 'n_per' in gdf_unif.columns:\n",
    "            gdf_unif.rename(columns={'n_per': 'TOTAL_PERS'}, inplace=True)\n",
    "        if 'MANZENT' not in gdf_unif.columns and 'UID' in gdf_unif.columns:\n",
    "            gdf_unif['MANZENT'] = gdf_unif['UID']\n",
    "\n",
    "        gdf_urban = gdf_unif[gdf_unif['TIPO_REGISTRO'] == 'MANZANA_URBANA'].copy()\n",
    "        rural_extra = gdf_unif[gdf_unif['TIPO_REGISTRO'] != 'MANZANA_URBANA'].copy()\n",
    "\n",
    "        if not gdf_urban.empty:\n",
    "            gdf_urban['TIPO_FUENTE'] = 'URBANO'\n",
    "            frames_censo = [gdf_urban]\n",
    "        else:\n",
    "            print(\"Advertencia: el parquet unificado no trae MANZANA_URBANA. Se conserva manzanas base.\")\n",
    "\n",
    "        if not rural_extra.empty:\n",
    "            rural_extra['TIPO_FUENTE'] = 'RURAL'\n",
    "            if 'MANZENT' not in rural_extra.columns and 'UID' in rural_extra.columns:\n",
    "                rural_extra['MANZENT'] = rural_extra['UID']\n",
    "            if 'TOTAL_PERS' not in rural_extra.columns and 'n_per' in rural_extra.columns:\n",
    "                rural_extra.rename(columns={'n_per': 'TOTAL_PERS'}, inplace=True)\n",
    "            frames_censo.append(rural_extra)\n",
    "            print(f\"Rural agregado desde parquet unificado: {len(rural_extra):,} filas\")\n",
    "\n",
    "manzanas = pd.concat(frames_censo, ignore_index=True)\n",
    "print(f\"Censo cargado: urbano+rural {len(manzanas):,} registros\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. PREPARACIÓN DE DATOS (NIVEL MANZANA/LOCALIDAD)\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 3: Preparando Datos (Nivel Manzana/Localidad) ---\")\n",
    "\n",
    "manzanas_full = manzanas.copy()\n",
    "\n",
    "# 1. Asegurar ID Único de Manzana (MANZENT)\n",
    "if 'MANZENT' in manzanas_full.columns:\n",
    "    # Handle both numeric and string MANZENT values\n",
    "    if pd.api.types.is_numeric_dtype(manzanas_full['MANZENT']):\n",
    "        manzanas_full['MANZENT'] = manzanas_full['MANZENT'].fillna(0).astype('int64').astype(str)\n",
    "    else:\n",
    "        manzanas_full['MANZENT'] = manzanas_full['MANZENT'].fillna('UNKNOWN').astype(str)\n",
    "else:\n",
    "    print(\"ADVERTENCIA: No se encontró MANZENT. Creando ID sintético.\")\n",
    "    manzanas_full['MANZENT'] = manzanas_full.index.astype(str)\n",
    "\n",
    "# 2. Rellenar Nulos en Jerarquía\n",
    "cols_fill = {\n",
    "    'ID_ENTIDAD': 0,\n",
    "    'ENTIDAD': 'DESCONOCIDA',\n",
    "    'CATEGORIA': 'DESCONOCIDA',\n",
    "    'LOCALIDAD': 'DESCONOCIDA',\n",
    "    'AREA_C': 'DESCONOCIDA',\n",
    "    'COMUNA': 'DESCONOCIDA',\n",
    "    'TIPO_FUENTE': 'URBANO'\n",
    "}\n",
    "\n",
    "for col, val in cols_fill.items():\n",
    "    if col not in manzanas_full.columns:\n",
    "        manzanas_full[col] = val\n",
    "    else:\n",
    "        if col == 'ID_ENTIDAD':\n",
    "             manzanas_full[col] = manzanas_full[col].fillna(0).astype('int64')\n",
    "        else:\n",
    "             manzanas_full[col] = manzanas_full[col].fillna(val)\n",
    "\n",
    "# Ajuste específico para ID_ENTIDAD=0 -> Rural\n",
    "mask_rural = manzanas_full['ID_ENTIDAD'] == 0\n",
    "manzanas_full.loc[mask_rural, 'ENTIDAD'] = 'DISPERSO / RURAL'\n",
    "manzanas_full.loc[mask_rural, 'CATEGORIA'] = 'DISPERSO'\n",
    "\n",
    "# Normalizar Comuna\n",
    "manzanas_full['COMUNA_NORM'] = manzanas_full['COMUNA'].apply(normalize_text)\n",
    "\n",
    "# Proyección UTM\n",
    "print(\"Proyectando a UTM 19S...\")\n",
    "manzanas_utm = manzanas_full.to_crs(epsg=32719)\n",
    "gdf_pudo_utm = gdf_PUDO.to_crs(epsg=32719)\n",
    "\n",
    "# Para geometrías puntuales (típicas en rural), agregar un pequeño buffer para permitir cálculo de área/cobertura\n",
    "is_point_geom = manzanas_utm.geometry.geom_type.isin(['Point', 'MultiPoint'])\n",
    "if is_point_geom.any():\n",
    "    manzanas_utm.loc[is_point_geom, 'geometry'] = manzanas_utm.loc[is_point_geom].geometry.buffer(1)\n",
    "\n",
    "# ==========================================\n",
    "# 4. CÁLCULO DE COBERTURA POR MANZANA/LOCALIDAD\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 4: Calculando Cobertura por Manzana/Localidad ---\")\n",
    "\n",
    "resultados_manzanas = []\n",
    "grupos_comuna = manzanas_utm.groupby('COMUNA_NORM')\n",
    "total = len(grupos_comuna)\n",
    "count = 0\n",
    "\n",
    "for comuna_norm, df_mz_comuna in grupos_comuna:\n",
    "    count += 1\n",
    "    if count % 20 == 0:\n",
    "        print(f\"Procesando Comuna {count}/{total}: {comuna_norm}\")\n",
    "\n",
    "    # Filtrar PUDOs\n",
    "    pudos_comuna = gdf_pudo_utm[gdf_pudo_utm['COMUNA_NORM'] == comuna_norm]\n",
    "    \n",
    "    # Preparar datos base de la comuna\n",
    "    df_mz_comuna = df_mz_comuna.copy()\n",
    "    df_mz_comuna['area_total_m2'] = df_mz_comuna.geometry.area\n",
    "    df_mz_comuna['area_total_m2'] = df_mz_comuna['area_total_m2'].replace(0, 1.0)\n",
    "    \n",
    "    # Columnas a guardar\n",
    "    cols_output = [\n",
    "        'MANZENT', 'COMUNA', 'ENTIDAD', 'CATEGORIA', 'LOCALIDAD', 'AREA_C', 'TIPO_FUENTE',\n",
    "        'TOTAL_PERS', 'area_total_m2', 'ID_ENTIDAD', 'ID_LOCALIDAD'\n",
    "    ]\n",
    "    cols_validas = [c for c in cols_output if c in df_mz_comuna.columns]\n",
    "    \n",
    "    # Indexar por MANZENT para mapeo rápido\n",
    "    base_data = df_mz_comuna[cols_validas].set_index('MANZENT')\n",
    "    \n",
    "    # Inicializar métricas\n",
    "    base_data['area_cubierta_m2'] = 0.0\n",
    "    base_data['pudos_en_comuna'] = len(pudos_comuna)\n",
    "    base_data['pudos_en_manzana'] = 0\n",
    "\n",
    "    if not pudos_comuna.empty:\n",
    "        try:\n",
    "            # --- A. CÁLCULO DE COBERTURA (ÁREA) ---\n",
    "            buffer_union = pudos_comuna.geometry.buffer(800).unary_union\n",
    "            gdf_buffer = gpd.GeoDataFrame(geometry=[buffer_union], crs=df_mz_comuna.crs)\n",
    "            \n",
    "            interseccion = gpd.overlay(df_mz_comuna, gdf_buffer, how='intersection')\n",
    "            \n",
    "            if not interseccion.empty:\n",
    "                interseccion['area_pedazo'] = interseccion.geometry.area\n",
    "                areas_cubiertas = interseccion.groupby('MANZENT')['area_pedazo'].sum()\n",
    "                base_data.loc[areas_cubiertas.index, 'area_cubierta_m2'] = areas_cubiertas\n",
    "            \n",
    "            # --- B. CONTEO DE PUDOS CERCANOS (Por Manzana/Localidad) ---\n",
    "            pudos_buffers = pudos_comuna.copy()\n",
    "            pudos_buffers['geometry'] = pudos_buffers.geometry.buffer(800)\n",
    "            \n",
    "            geom_col_name = df_mz_comuna.geometry.name\n",
    "            mz_for_sjoin = df_mz_comuna[['MANZENT', geom_col_name]].copy()\n",
    "            mz_for_sjoin = gpd.GeoDataFrame(mz_for_sjoin, geometry=geom_col_name, crs=df_mz_comuna.crs)\n",
    "            \n",
    "            joined_pudos = gpd.sjoin(mz_for_sjoin, pudos_buffers[['geometry']], how='inner', predicate='intersects')\n",
    "            \n",
    "            counts_pudos = joined_pudos.groupby('MANZENT').size()\n",
    "            base_data.loc[counts_pudos.index, 'pudos_en_manzana'] = counts_pudos\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en comuna {comuna_norm}: {e}\")\n",
    "\n",
    "    # Calcular Porcentajes y Población\n",
    "    base_data['pct_cobertura'] = (base_data['area_cubierta_m2'] / base_data['area_total_m2']).fillna(0.0)\n",
    "    base_data['pct_cobertura'] = base_data['pct_cobertura'].clip(upper=1.0)\n",
    "    \n",
    "    base_data['pob_cubierta'] = base_data['TOTAL_PERS'] * base_data['pct_cobertura']\n",
    "    \n",
    "    resultados_manzanas.append(base_data.reset_index())\n",
    "\n",
    "# ==========================================\n",
    "# 5. CONSOLIDACIÓN Y GUARDADO\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 5: Guardando Reporte Granular ---\")\n",
    "\n",
    "if resultados_manzanas:\n",
    "    df_final = pd.concat(resultados_manzanas, ignore_index=True)\n",
    "    \n",
    "    df_final['pob_cubierta'] = df_final['pob_cubierta'].round(2)\n",
    "    df_final['pct_cobertura'] = df_final['pct_cobertura'].round(4)\n",
    "    df_final['area_cubierta_m2'] = df_final['area_cubierta_m2'].round(1)\n",
    "    df_final['area_total_m2'] = df_final['area_total_m2'].round(1)\n",
    "    \n",
    "    df_final['pudos_en_manzana'] = df_final['pudos_en_manzana'].astype(int)\n",
    "    df_final['pudos_en_comuna'] = df_final['pudos_en_comuna'].astype(int)\n",
    "    \n",
    "    df_final = df_final.sort_values(by=['COMUNA', 'ENTIDAD', 'MANZENT'])\n",
    "    \n",
    "    filename = 'Cobertura_Censo24_Por_Manzana.xlsx'\n",
    "    \n",
    "    print(f\"Generando Excel con {len(df_final)} filas...\")\n",
    "    #df_final.to_excel(filename, index=False)\n",
    "    print(f\"Archivo generado: {filename}\")\n",
    "else:\n",
    "    print(\"No se generaron resultados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdeae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18226208.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['TOTAL_PERS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b580623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244756"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manzanas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13e8387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paso 6: Generando Reporte Agrupado (Aldea/Localidad) ---\n",
      "Agrupando datos por COMUNA y LOCALIDAD (sin AREA_C)...\n",
      "Calculando PUDOs por Localidad (solo puntos dentro de la comuna)...\n",
      "\n",
      "✅  Todas las comunas cuadran perfectamente (PUDOs Comuna vs Suma Localidades).\n",
      "Archivo de resumen generado: Cobertura_Censo24_Resumen_Localidad.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. GENERACIÓN DE REPORTE AGRUPADO (ALDEA/LOCALIDAD)\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 6: Generando Reporte Agrupado (Aldea/Localidad) ---\")\n",
    "\n",
    "if 'df_final' in locals() and not df_final.empty:\n",
    "    print(\"Agrupando datos por COMUNA y LOCALIDAD (sin AREA_C)...\")\n",
    "    \n",
    "    cols_group = ['COMUNA', 'LOCALIDAD']\n",
    "    \n",
    "    df_agrupado = df_final.groupby(cols_group).agg({\n",
    "        'TOTAL_PERS': 'sum',\n",
    "        'pob_cubierta': 'sum',\n",
    "        'area_total_m2': 'sum',\n",
    "        'area_cubierta_m2': 'sum',\n",
    "        'pudos_en_comuna': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    df_agrupado['PORCENTAJE_COBERTURA'] = (df_agrupado['pob_cubierta'] / df_agrupado['TOTAL_PERS']).fillna(0)\n",
    "\n",
    "    # Identificación única de PUDOs\n",
    "    gdf_pudo_counts = gdf_pudo_utm.copy()\n",
    "    id_col = 'esto_seq_cdg' if 'esto_seq_cdg' in gdf_pudo_counts.columns else ('PUDO_ID' if 'PUDO_ID' in gdf_pudo_counts.columns else None)\n",
    "    \n",
    "    if id_col is None:\n",
    "        gdf_pudo_counts['PUDO_ID_WORK'] = (-1000 * pd.Series(gdf_pudo_counts.index, index=gdf_pudo_counts.index)).astype(int)\n",
    "    else:\n",
    "        gdf_pudo_counts['PUDO_ID_WORK'] = gdf_pudo_counts[id_col].fillna((-1000 * pd.Series(gdf_pudo_counts.index, index=gdf_pudo_counts.index)).astype(int))\n",
    "    \n",
    "    gdf_pudo_counts = gdf_pudo_counts.drop_duplicates(subset=['PUDO_ID_WORK'])\n",
    "    gdf_pudo_counts['COMUNA_NORM'] = gdf_pudo_counts['COMUNA_NORM'].fillna('').astype(str)\n",
    "    \n",
    "    # --- CÁLCULO DE PUDOS POR LOCALIDAD ---\n",
    "    print(\"Calculando PUDOs por Localidad (solo puntos dentro de la comuna)...\")\n",
    "    \n",
    "    pudos_por_localidad = {}\n",
    "    extra_rows = []\n",
    "    \n",
    "    # Diccionario maestro de totales reales\n",
    "    pudos_por_comuna_real = {}\n",
    "\n",
    "    for comuna in df_agrupado['COMUNA'].unique():\n",
    "        comuna_norm = normalize_text(comuna)\n",
    "        \n",
    "        # 1. Obtener PUDOs base por nombre normalizado\n",
    "        pudos_comuna_base = gdf_pudo_counts[gdf_pudo_counts['COMUNA_NORM'] == comuna_norm][['PUDO_ID_WORK', 'geometry']].copy()\n",
    "        \n",
    "        # Guardar total teórico inicial\n",
    "        pudos_por_comuna_real[comuna_norm] = len(pudos_comuna_base)\n",
    "\n",
    "        mz_comuna_full = manzanas_utm[manzanas_utm['COMUNA_NORM'] == comuna_norm].copy()\n",
    "        \n",
    "        if mz_comuna_full.empty or pudos_comuna_base.empty:\n",
    "            continue\n",
    "            \n",
    "        geom_col_mz = mz_comuna_full.geometry.name or 'geometry'\n",
    "\n",
    "        # 2. Rellenar LOCALIDAD si falta\n",
    "        if 'LOCALIDAD' not in mz_comuna_full.columns:\n",
    "             mz_comuna_full['LOCALIDAD'] = 'DESCONOCIDA'\n",
    "        mz_comuna_full['LOCALIDAD'] = mz_comuna_full['LOCALIDAD'].fillna('DESCONOCIDA').astype(str)\n",
    "\n",
    "        # 3. Filtrar columnas necesarias\n",
    "        cols_select = list(set(['LOCALIDAD', geom_col_mz]))\n",
    "        mz_comuna = gpd.GeoDataFrame(mz_comuna_full[cols_select].copy(), geometry=geom_col_mz, crs=mz_comuna_full.crs)\n",
    "\n",
    "        try:\n",
    "            # 4. Asignación Espacial (Nearest)\n",
    "            # Primero intentamos con radio 1km\n",
    "            pudos_con_localidad = gpd.sjoin_nearest(\n",
    "                pudos_comuna_base[['PUDO_ID_WORK', 'geometry']],\n",
    "                mz_comuna,\n",
    "                how='left',\n",
    "                max_distance=1000\n",
    "            )\n",
    "\n",
    "            # Fallback para los que quedaron NaN (más lejos de 1km) -> Asignar al más cercano sin límite\n",
    "            if pudos_con_localidad['LOCALIDAD'].isna().any():\n",
    "                missing_mask = pudos_con_localidad['LOCALIDAD'].isna()\n",
    "                missing_ids = pudos_con_localidad.loc[missing_mask, 'PUDO_ID_WORK'].unique()\n",
    "                \n",
    "                missing_pudos = pudos_comuna_base[pudos_comuna_base['PUDO_ID_WORK'].isin(missing_ids)]\n",
    "                \n",
    "                fallback_matches = gpd.sjoin_nearest(\n",
    "                    missing_pudos[['PUDO_ID_WORK', 'geometry']],\n",
    "                    mz_comuna,\n",
    "                    how='left'\n",
    "                )\n",
    "                \n",
    "                # Actualizar los valores NaN con los del fallback\n",
    "                # Mapear ID -> Localidad del fallback\n",
    "                fallback_map = fallback_matches.set_index('PUDO_ID_WORK')['LOCALIDAD'].to_dict()\n",
    "                pudos_con_localidad['LOCALIDAD'] = pudos_con_localidad.apply(\n",
    "                    lambda row: fallback_map.get(row['PUDO_ID_WORK'], row['LOCALIDAD']) if pd.isna(row['LOCALIDAD']) else row['LOCALIDAD'],\n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "            # Relleno final por seguridad\n",
    "            pudos_con_localidad['LOCALIDAD'] = pudos_con_localidad['LOCALIDAD'].fillna('SIN_LOCALIDAD')\n",
    "\n",
    "            # 5. Conteo Único\n",
    "            pudos_unique_loc = pudos_con_localidad[['PUDO_ID_WORK', 'LOCALIDAD']].drop_duplicates(subset=['PUDO_ID_WORK'])\n",
    "            conteo = pudos_unique_loc.groupby('LOCALIDAD')['PUDO_ID_WORK'].nunique()\n",
    "            \n",
    "            # Guardar en diccionario global\n",
    "            for locality, count in conteo.items():\n",
    "                pudos_por_localidad[(comuna, str(locality))] = int(count)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error procesando PUDOs en {comuna}: {e}\")\n",
    "\n",
    "    # --- INYECCIÓN DE LOCALIDADES FALTANTES ---\n",
    "    # Verificar si hay claves en pudos_por_localidad que NO están en df_agrupado\n",
    "    # Esto ocurre si un PUDO cae en una localidad que no tenía manzanas en el reporte final (raro) o por discrepancia de nombres\n",
    "    \n",
    "    existing_keys = set(zip(df_agrupado['COMUNA'], df_agrupado['LOCALIDAD'].astype(str)))\n",
    "    new_rows = []\n",
    "    \n",
    "    for (c_key, l_key), count_val in pudos_por_localidad.items():\n",
    "        if (c_key, l_key) not in existing_keys:\n",
    "            # Crear fila nueva\n",
    "            print(f\"  > Agregando localidad faltante al reporte: {c_key} - {l_key} ({count_val} PUDOs)\")\n",
    "            new_rows.append({\n",
    "                'COMUNA': c_key,\n",
    "                'LOCALIDAD': l_key,\n",
    "                'TOTAL_PERS': 0,\n",
    "                'pob_cubierta': 0,\n",
    "                'area_total_m2': 0,\n",
    "                'area_cubierta_m2': 0,\n",
    "                'pudos_en_comuna': pudos_por_comuna_real.get(normalize_text(c_key), 0),\n",
    "                'CANTIDAD_PUDOS_LOCALIDAD': count_val\n",
    "            })\n",
    "\n",
    "    if new_rows:\n",
    "        df_new = pd.DataFrame(new_rows)\n",
    "        df_agrupado = pd.concat([df_agrupado, df_new], ignore_index=True)\n",
    "\n",
    "    # --- ASIGNACIÓN FINAL DE CONTEOS ---\n",
    "    # Iterar nuevamente para asegurar que todos tengan valor (los existentes y los nuevos)\n",
    "    for idx, row in df_agrupado.iterrows():\n",
    "        c_key = row['COMUNA']\n",
    "        l_key = str(row['LOCALIDAD'])\n",
    "        \n",
    "        # Asignar conteo\n",
    "        cnt = pudos_por_localidad.get((c_key, l_key), 0)\n",
    "        df_agrupado.at[idx, 'CANTIDAD_PUDOS_LOCALIDAD'] = cnt\n",
    "        \n",
    "        # Asignar total comunal real\n",
    "        cnorm = normalize_text(c_key)\n",
    "        df_agrupado.at[idx, 'pudos_en_comuna'] = pudos_por_comuna_real.get(cnorm, 0)\n",
    "\n",
    "    # Formateo final\n",
    "    cols_check = ['CANTIDAD_PUDOS_LOCALIDAD', 'pudos_en_comuna', 'TOTAL_PERS', 'pob_cubierta']\n",
    "    for col in cols_check:\n",
    "        df_agrupado[col] = df_agrupado[col].fillna(0).astype(int)\n",
    "\n",
    "    df_agrupado['PORCENTAJE_COBERTURA'] = (df_agrupado['pob_cubierta'] / df_agrupado['TOTAL_PERS'].replace(0, 1)).fillna(0).round(4)\n",
    "    \n",
    "    # Diagnóstico de cuadratura\n",
    "    mismatch_rows = []\n",
    "    for comuna in df_agrupado['COMUNA'].unique():\n",
    "        sub = df_agrupado[df_agrupado['COMUNA'] == comuna]\n",
    "        total_real = sub['pudos_en_comuna'].iloc[0] # Debería ser igual en todas las filas de la comuna\n",
    "        suma_loc = sub['CANTIDAD_PUDOS_LOCALIDAD'].sum()\n",
    "        \n",
    "        if total_real != suma_loc:\n",
    "            mismatch_rows.append({\n",
    "                'COMUNA': comuna,\n",
    "                'REAL': total_real,\n",
    "                'SUMA_LOC': suma_loc,\n",
    "                'DIF': total_real - suma_loc\n",
    "            })\n",
    "            \n",
    "    if mismatch_rows:\n",
    "        mismatch_df = pd.DataFrame(mismatch_rows).sort_values(by='DIF', ascending=False)\n",
    "        print(\"\\n⚠️  ALERTA DE DESCUADRE (Top 10):\")\n",
    "        print(mismatch_df.head(10))\n",
    "    else:\n",
    "        print(\"\\n✅  Todas las comunas cuadran perfectamente (PUDOs Comuna vs Suma Localidades).\")\n",
    "\n",
    "    # Columnas internas (usando los nombres reales del DataFrame)\n",
    "    cols_final_internal = [\n",
    "        'COMUNA', 'LOCALIDAD',\n",
    "        'TOTAL_PERS', 'pob_cubierta', 'PORCENTAJE_COBERTURA',\n",
    "        'CANTIDAD_PUDOS_LOCALIDAD', 'pudos_en_comuna'\n",
    "    ]\n",
    "    \n",
    "    df_resumen = df_agrupado[cols_final_internal].sort_values(by=['COMUNA', 'LOCALIDAD'])\n",
    "    \n",
    "    # Renombrar para exportación (User-Friendly names)\n",
    "    df_resumen = df_resumen.rename(columns={\n",
    "        'TOTAL_PERS': 'POBLACION_TOTAL',\n",
    "        'pob_cubierta': 'POBLACION_CUBIERTA'\n",
    "    })\n",
    "    \n",
    "    filename_resumen = 'Cobertura_Censo24_Resumen_Localidad.xlsx'\n",
    "    try:\n",
    "        df_resumen.to_excel(filename_resumen, index=False)\n",
    "    except PermissionError:\n",
    "        alt_name = 'Cobertura_Censo24_Resumen_Localidad_alt.xlsx'\n",
    "        print(f\"Aviso: '{filename_resumen}' está bloqueado. Guardando en '{alt_name}'\")\n",
    "        df_resumen.to_excel(alt_name, index=False)\n",
    "        filename_resumen = alt_name\n",
    "    print(f\"Archivo de resumen generado: {filename_resumen}\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: No se encontró el DataFrame 'df_final'. Ejecuta el paso anterior primero.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e093003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paso 6.1: Generando reporte por PUDO (incluyendo Partners) ---\n",
      "Cargando Partners desde CSV...\n",
      "   Partners cargados: 649\n",
      "Total puntos a analizar (PUDOs + Partners): 4073\n",
      "   Procesando comuna 20/329: RENGO\n",
      "   Procesando comuna 40/329: QUINTA NORMAL\n",
      "   Procesando comuna 60/329: CHIGUAYANTE\n",
      "   Procesando comuna 80/329: ANGOL\n",
      "   Procesando comuna 100/329: COIHUECO\n",
      "   Procesando comuna 120/329: LO ESPEJO\n",
      "   Procesando comuna 140/329: COYHAIQUE\n",
      "   Procesando comuna 160/329: CHIMBARONGO\n",
      "   Procesando comuna 180/329: MARIA PINTO\n",
      "   Procesando comuna 200/329: TALAGANTE\n",
      "   Procesando comuna 220/329: PAREDONES\n",
      "   Procesando comuna 240/329: SAN JUAN DE LA COSTA\n",
      "   Procesando comuna 260/329: LUMACO\n",
      "   Procesando comuna 280/329: PEUMO\n",
      "   Procesando comuna 300/329: PUMANQUE\n",
      "   Procesando comuna 320/329: SANTA BARBARA\n",
      "\n",
      "✅ Archivo generado: Cobertura_Por_PUDO_y_Partners.xlsx\n",
      "   Total registros: 4,073\n",
      "   - PUDOs: 3,424\n",
      "   - Partners: 649\n",
      "\n",
      "Ejemplo de datos:\n",
      "   PUDO_ID  AGENCY_ID                                  OFCN_DSC  Q_DAO_PROPIO  \\\n",
      "0        1        1.0          DROP OFF BX LIMITADA PRUEBA PROD          37.0   \n",
      "1      100      100.0       Punto Blue Express Donde La Silvita           9.0   \n",
      "2      902      902.0              Punto Blue Express Los Pinos          23.0   \n",
      "3     1163     1163.0        Punto Blue Express Store Nutrition          12.0   \n",
      "4     1180     1180.0               Punto Blue Express Ms Tecno          30.0   \n",
      "5     1506     1506.0   Punto Blue Express Abastible El Shaddai          13.0   \n",
      "6     2053     2053.0  Punto Blue Express Ferreteria Libertador          20.0   \n",
      "7     2093     2093.0     Punto Blue Express Correo Puente Alto           8.0   \n",
      "8     2167     2167.0    Punto Blue Express Copec Gabriela 3950         100.0   \n",
      "9     2168     2168.0  Punto Blue Express Copec Eyzaguirre 2436          53.0   \n",
      "\n",
      "   POTENCIAL_ROBO_Q       COMUNA      LOCALIDAD        LAT        LON  \\\n",
      "0             18.61  PUENTE ALTO  GRAN SANTIAGO -33.564457 -70.545033   \n",
      "1            156.65  PUENTE ALTO  GRAN SANTIAGO -33.563148 -70.559960   \n",
      "2            242.79  PUENTE ALTO  GRAN SANTIAGO -33.578504 -70.598536   \n",
      "3            199.16  PUENTE ALTO  GRAN SANTIAGO -33.587912 -70.599674   \n",
      "4             32.42  PUENTE ALTO  GRAN SANTIAGO -33.568170 -70.571552   \n",
      "5             84.80  PUENTE ALTO  GRAN SANTIAGO -33.603628 -70.564920   \n",
      "6             80.30  PUENTE ALTO  GRAN SANTIAGO -33.591637 -70.596235   \n",
      "7             92.70  PUENTE ALTO  GRAN SANTIAGO -33.578312 -70.587509   \n",
      "8            163.59  PUENTE ALTO  GRAN SANTIAGO -33.582491 -70.606163   \n",
      "9              3.89  PUENTE ALTO  GRAN SANTIAGO -33.615854 -70.602986   \n",
      "\n",
      "   POBLACION_CUBIERTA_PUDO  POBLACION_UNICA_PUDO  PUDOS_OVERLAP_BUFFERS  \\\n",
      "0                    11732                     0                     13   \n",
      "1                    15457                     0                     13   \n",
      "2                    27529                     0                     15   \n",
      "3                    36216                     0                     16   \n",
      "4                    29265                  7519                     16   \n",
      "5                    25651                  3399                     18   \n",
      "6                    32010                     0                     14   \n",
      "7                    16528                     0                     17   \n",
      "8                    25171                     0                     12   \n",
      "9                    17143                  4876                      4   \n",
      "\n",
      "   q_vecinos_reales  q_blue  q_copec  q_partner TIPO_PUNTO  IS_PARTNER  \n",
      "0                 2       2        0          0       blue       False  \n",
      "1                 9       5        2          2       blue       False  \n",
      "2                 4       3        1          0       blue       False  \n",
      "3                 5       4        1          0       blue       False  \n",
      "4                 0       0        0          0       blue       False  \n",
      "5                 0       0        0          0       blue       False  \n",
      "6                 2       2        0          0       blue       False  \n",
      "7                 3       3        0          0       blue       False  \n",
      "8                 5       4        1          0      copec       False  \n",
      "9                 0       0        0          0      copec       False  \n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6.1 GENERACIÓN DE REPORTE POR PUDO (+ PARTNERS)\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 6.1: Generando reporte por PUDO (incluyendo Partners) ---\")\n",
    "\n",
    "if gdf_PUDO is None or gdf_PUDO.empty:\n",
    "    print(\"No se encontraron PUDOs para procesar.\")\n",
    "elif 'manzanas_utm' not in locals():\n",
    "    print(\"Error: faltan datos de manzanas (ejecute pasos anteriores).\")\n",
    "else:\n",
    "    # Preparación de insumos - VERSION MEJORADA CON VALIDACIÓN (sin AREA_C)\n",
    "    cols_needed = ['MANZENT', 'TOTAL_PERS', 'LOCALIDAD', 'COMUNA', 'COMUNA_NORM', 'geometry']\n",
    "    cols_available = [c for c in cols_needed if c in manzanas_utm.columns]\n",
    "    geom_col = manzanas_utm.geometry.name\n",
    "    if geom_col not in cols_available:\n",
    "        cols_available.append(geom_col)\n",
    "    \n",
    "    try:\n",
    "        manzanas_work = gpd.GeoDataFrame(\n",
    "            manzanas_utm[cols_available].copy(),\n",
    "            geometry=geom_col,\n",
    "            crs=manzanas_utm.crs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error seleccionando columnas de manzanas_utm: {e}\")\n",
    "        print(f\"Columnas disponibles: {list(manzanas_utm.columns)}\")\n",
    "        print(\"Abortando Paso 6.1\")\n",
    "        manzanas_work = None\n",
    "    \n",
    "    if manzanas_work is not None and not manzanas_work.empty:\n",
    "        geom_col_work = manzanas_work.geometry.name\n",
    "        manzanas_work['area_m2'] = manzanas_work.geometry.area\n",
    "        manzanas_work['area_m2'] = manzanas_work['area_m2'].replace(0, 1.0)\n",
    "        manzanas_area_map = manzanas_work.set_index('MANZENT')['area_m2']\n",
    "        \n",
    "        # --- Cargar catálogo de agencias (lat/lon reales y tipo_punto) ---\n",
    "        try:\n",
    "            agencias_raw = pd.read_csv(\"data/partners_blue_capilaridad_qos.csv\")\n",
    "            agencias_raw['geol_latitud'] = agencias_raw['geol_latitud'].astype(str).str.replace(',', '.').astype(float)\n",
    "            agencias_raw['geol_longitud'] = agencias_raw['geol_longitud'].astype(str).str.replace(',', '.').astype(float)\n",
    "            agencias_raw['ofcn_dsc'] = agencias_raw.get('ofcn_dsc', '').astype(str).str.strip()\n",
    "            agencias_raw['q_dao'] = pd.to_numeric(agencias_raw.get('q_dao', 0), errors='coerce').fillna(0)\n",
    "            \n",
    "            gdf_ag_wgs = gpd.GeoDataFrame(\n",
    "                agencias_raw,\n",
    "                geometry=gpd.points_from_xy(agencias_raw.geol_longitud, agencias_raw.geol_latitud),\n",
    "                crs=\"EPSG:4326\"\n",
    "            )\n",
    "            gdf_ag_wgs['COMUNA_NORM'] = gdf_ag_wgs['cmns_nmb'].apply(normalize_text)\n",
    "            gdf_ag_wgs['tipo_punto_std'] = gdf_ag_wgs['tipo_punto'].astype(str).str.strip().str.lower()\n",
    "            gdf_ag_wgs['lat_round'] = gdf_ag_wgs.geometry.y.round(6)\n",
    "            gdf_ag_wgs['lon_round'] = gdf_ag_wgs.geometry.x.round(6)\n",
    "            gdf_ag_wgs = gdf_ag_wgs.sort_values('agencyid').drop_duplicates(subset=['lat_round', 'lon_round'], keep='first')\n",
    "            gdf_ag_utm = gdf_ag_wgs.to_crs(epsg=32719)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando catálogo de agencias: {e}\")\n",
    "            gdf_ag_wgs = gpd.GeoDataFrame(columns=['agencyid', 'tipo_punto_std', 'geometry'], crs=\"EPSG:4326\")\n",
    "            gdf_ag_utm = gpd.GeoDataFrame(columns=['agencyid', 'tipo_punto_std', 'geometry'], crs=\"EPSG:32719\")\n",
    "        \n",
    "        # --- NUEVO: Cargar Partners desde CSV ---\n",
    "        try:\n",
    "            print(\"Cargando Partners desde CSV...\")\n",
    "            partners_raw = pd.read_csv(\"data/partners_mapa.csv\")\n",
    "            partners_raw['lat'] = pd.to_numeric(partners_raw.get('lat', 0), errors='coerce').fillna(0)\n",
    "            partners_raw['lon'] = pd.to_numeric(partners_raw.get('lon', 0), errors='coerce').fillna(0)\n",
    "            partners_raw = partners_raw[(partners_raw['lat'] != 0) & (partners_raw['lon'] != 0)]\n",
    "            \n",
    "            if not partners_raw.empty:\n",
    "                gdf_partners_wgs = gpd.GeoDataFrame(\n",
    "                    partners_raw,\n",
    "                    geometry=gpd.points_from_xy(partners_raw.lon, partners_raw.lat),\n",
    "                    crs=\"EPSG:4326\"\n",
    "                )\n",
    "                gdf_partners_wgs['lat_round'] = gdf_partners_wgs.geometry.y.round(6)\n",
    "                gdf_partners_wgs['lon_round'] = gdf_partners_wgs.geometry.x.round(6)\n",
    "                gdf_partners_wgs = gdf_partners_wgs.drop_duplicates(subset=['lat_round', 'lon_round'], keep='first')\n",
    "                gdf_partners_utm = gdf_partners_wgs.to_crs(epsg=32719)\n",
    "                gdf_partners_utm['OFCN_DSC'] = gdf_partners_utm.get('Partner/Tipo', '').astype(str).str.strip()\n",
    "                gdf_partners_utm['Q_DAO'] = 0\n",
    "                gdf_partners_utm['TIPO_PUNTO'] = 'partner'\n",
    "                print(f\"   Partners cargados: {len(gdf_partners_utm)}\")\n",
    "            else:\n",
    "                gdf_partners_utm = gpd.GeoDataFrame(columns=['geometry', 'OFCN_DSC', 'Q_DAO', 'TIPO_PUNTO'], crs=\"EPSG:32719\")\n",
    "                print(\"   No se encontraron partners con coordenadas válidas\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando partners: {e}\")\n",
    "            gdf_partners_utm = gpd.GeoDataFrame(columns=['geometry', 'OFCN_DSC', 'Q_DAO', 'TIPO_PUNTO'], crs=\"EPSG:32719\")\n",
    "        \n",
    "        # --- Procesar PUDOs base ---\n",
    "        gdf_pudo_work = gdf_pudo_utm.copy()\n",
    "        if 'esto_seq_cdg' in gdf_pudo_work.columns:\n",
    "            gdf_pudo_work['PUDO_ID'] = gdf_pudo_work['esto_seq_cdg']\n",
    "        elif 'PUDO_ID' in gdf_pudo_work.columns:\n",
    "            gdf_pudo_work['PUDO_ID'] = gdf_pudo_work['PUDO_ID']\n",
    "        else:\n",
    "            gdf_pudo_work['PUDO_ID'] = (-1000 * pd.Series(gdf_pudo_work.index, index=gdf_pudo_work.index)).astype(int)\n",
    "        gdf_pudo_work['PUDO_ID'] = gdf_pudo_work['PUDO_ID'].fillna((-1000 * pd.Series(gdf_pudo_work.index, index=gdf_pudo_work.index)).astype(int))\n",
    "        \n",
    "        gdf_pudo_work['COMUNA'] = gdf_pudo_work.get('cmns_nmb', gdf_pudo_work.get('COMUNA', ''))\n",
    "        gdf_pudo_work['COMUNA'] = gdf_pudo_work['COMUNA'].fillna('').astype(str)\n",
    "        if 'COMUNA_NORM' not in gdf_pudo_work.columns:\n",
    "            gdf_pudo_work['COMUNA_NORM'] = gdf_pudo_work['COMUNA'].apply(normalize_text)\n",
    "        else:\n",
    "            gdf_pudo_work['COMUNA_NORM'] = gdf_pudo_work['COMUNA_NORM'].apply(lambda x: normalize_text(str(x)) if pd.notna(x) else '')\n",
    "        gdf_pudo_work['COMUNA_NORM'] = gdf_pudo_work['COMUNA_NORM'].astype(str)\n",
    "        \n",
    "        gdf_pudo_wgs = gdf_PUDO.copy()\n",
    "        gdf_pudo_wgs['lat'] = gdf_pudo_wgs.geometry.y\n",
    "        gdf_pudo_wgs['lon'] = gdf_pudo_wgs.geometry.x\n",
    "        gdf_pudo_wgs['lat_round'] = gdf_pudo_wgs['lat'].round(6)\n",
    "        gdf_pudo_wgs['lon_round'] = gdf_pudo_wgs['lon'].round(6)\n",
    "        pudo_coords = gdf_pudo_wgs[['lat', 'lon', 'lat_round', 'lon_round']].copy()\n",
    "        pudo_coords['PUDO_ID'] = gdf_pudo_work['PUDO_ID'].values\n",
    "        gdf_pudo_work = gdf_pudo_work.merge(\n",
    "            pudo_coords[['PUDO_ID', 'lat', 'lon', 'lat_round', 'lon_round']],\n",
    "            on='PUDO_ID',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        if not gdf_ag_wgs.empty:\n",
    "            gdf_pudo_work = gdf_pudo_work.merge(\n",
    "                gdf_ag_wgs[['agencyid', 'tipo_punto_std', 'q_dao', 'ofcn_dsc', 'lat_round', 'lon_round']],\n",
    "                on=['lat_round', 'lon_round'],\n",
    "                how='left',\n",
    "                suffixes=('', '_AG')\n",
    "            )\n",
    "        \n",
    "        if not gdf_ag_utm.empty:\n",
    "            faltantes_mask = gdf_pudo_work['agencyid'].isna()\n",
    "            if faltantes_mask.any():\n",
    "                pudo_missing = gdf_pudo_work.loc[faltantes_mask, ['PUDO_ID', 'geometry']].copy()\n",
    "                nearest_match = gpd.sjoin_nearest(\n",
    "                    gpd.GeoDataFrame(pudo_missing, geometry='geometry', crs=gdf_pudo_work.crs),\n",
    "                    gdf_ag_utm[['agencyid', 'tipo_punto_std', 'q_dao', 'ofcn_dsc', 'geometry']],\n",
    "                    how='left',\n",
    "                    max_distance=10\n",
    "                )\n",
    "                for _, r in nearest_match.iterrows():\n",
    "                    idx_pid = r['PUDO_ID']\n",
    "                    gdf_pudo_work.loc[gdf_pudo_work['PUDO_ID'] == idx_pid, 'agencyid'] = r.get('agencyid')\n",
    "                    gdf_pudo_work.loc[gdf_pudo_work['PUDO_ID'] == idx_pid, 'tipo_punto_std'] = r.get('tipo_punto_std')\n",
    "                    gdf_pudo_work.loc[gdf_pudo_work['PUDO_ID'] == idx_pid, 'q_dao'] = r.get('q_dao')\n",
    "                    gdf_pudo_work.loc[gdf_pudo_work['PUDO_ID'] == idx_pid, 'ofcn_dsc'] = r.get('ofcn_dsc')\n",
    "        \n",
    "        gdf_pudo_work['AGENCY_ID'] = gdf_pudo_work['agencyid']\n",
    "        gdf_pudo_work['TIPO_PUNTO_PUDO'] = gdf_pudo_work['tipo_punto_std']\n",
    "        gdf_pudo_work['OFCN_DSC'] = gdf_pudo_work.get('ofcn_dsc', '').fillna('').astype(str)\n",
    "        gdf_pudo_work['Q_DAO'] = gdf_pudo_work.get('q_dao', 0).fillna(0)\n",
    "        gdf_pudo_work['IS_PARTNER'] = False\n",
    "        \n",
    "        if not gdf_partners_utm.empty:\n",
    "            gdf_partners_utm['PUDO_ID'] = range(-1, -len(gdf_partners_utm)-1, -1)\n",
    "            gdf_partners_utm['AGENCY_ID'] = None\n",
    "            gdf_partners_utm['TIPO_PUNTO_PUDO'] = 'partner'\n",
    "            gdf_partners_utm['lat'] = gdf_partners_wgs.geometry.y.values\n",
    "            gdf_partners_utm['lon'] = gdf_partners_wgs.geometry.x.values\n",
    "            gdf_partners_utm['lat_round'] = gdf_partners_wgs['lat_round'].values\n",
    "            gdf_partners_utm['lon_round'] = gdf_partners_wgs['lon_round'].values\n",
    "            gdf_partners_utm['COMUNA'] = ''\n",
    "            gdf_partners_utm['COMUNA_NORM'] = ''\n",
    "            gdf_partners_utm['IS_PARTNER'] = True\n",
    "            \n",
    "            cols_mz_select = ['LOCALIDAD', 'COMUNA', 'COMUNA_NORM', 'geometry']\n",
    "            cols_mz_avail = [c for c in cols_mz_select if c in manzanas_work.columns]\n",
    "            if geom_col_work not in cols_mz_avail and geom_col_work in manzanas_work.columns:\n",
    "                cols_mz_avail.append(geom_col_work)\n",
    "            \n",
    "            if cols_mz_avail:\n",
    "                partners_for_join = gpd.GeoDataFrame(\n",
    "                    gdf_partners_utm[['PUDO_ID', 'geometry']].copy(),\n",
    "                    geometry='geometry',\n",
    "                    crs=gdf_partners_utm.crs\n",
    "                )\n",
    "                manzanas_for_join = gpd.GeoDataFrame(\n",
    "                    manzanas_work[cols_mz_avail].copy(),\n",
    "                    geometry=geom_col_work,\n",
    "                    crs=manzanas_work.crs\n",
    "                )\n",
    "                nearest_partner = gpd.sjoin_nearest(\n",
    "                    partners_for_join,\n",
    "                    manzanas_for_join,\n",
    "                    how='left',\n",
    "                    max_distance=800\n",
    "                )\n",
    "                cols_merge_p = [c for c in ['PUDO_ID', 'LOCALIDAD', 'COMUNA', 'COMUNA_NORM'] if c in nearest_partner.columns]\n",
    "                if cols_merge_p:\n",
    "                    gdf_partners_utm = gdf_partners_utm.merge(\n",
    "                        nearest_partner[cols_merge_p],\n",
    "                        on='PUDO_ID',\n",
    "                        how='left',\n",
    "                        suffixes=('', '_MZ')\n",
    "                    )\n",
    "                    # Deduplicar por ID para evitar expansión\n",
    "                    gdf_partners_utm = gdf_partners_utm.drop_duplicates(subset=['PUDO_ID'])\n",
    "\n",
    "                    if 'COMUNA_MZ' in gdf_partners_utm.columns:\n",
    "                        gdf_partners_utm['COMUNA'] = gdf_partners_utm['COMUNA_MZ'].fillna('').astype(str)\n",
    "                        gdf_partners_utm.drop(columns=['COMUNA_MZ'], inplace=True)\n",
    "                    if 'COMUNA_NORM_MZ' in gdf_partners_utm.columns:\n",
    "                        gdf_partners_utm['COMUNA_NORM'] = gdf_partners_utm['COMUNA_NORM_MZ'].fillna('').astype(str)\n",
    "                        gdf_partners_utm.drop(columns=['COMUNA_NORM_MZ'], inplace=True)\n",
    "        \n",
    "        cols_common_ext = ['PUDO_ID', 'AGENCY_ID', 'OFCN_DSC', 'Q_DAO', 'TIPO_PUNTO_PUDO', 'lat', 'lon', \n",
    "                          'lat_round', 'lon_round', 'COMUNA', 'COMUNA_NORM', 'IS_PARTNER', \n",
    "                          'LOCALIDAD_PUDO', 'geometry']\n",
    "        \n",
    "        if 'LOCALIDAD' in gdf_pudo_work.columns:\n",
    "            gdf_pudo_work['LOCALIDAD_PUDO'] = gdf_pudo_work['LOCALIDAD'].fillna('DESCONOCIDA').astype(str)\n",
    "        elif 'LOCALIDAD_PUDO' in gdf_pudo_work.columns:\n",
    "            gdf_pudo_work['LOCALIDAD_PUDO'] = gdf_pudo_work['LOCALIDAD_PUDO'].fillna('DESCONOCIDA').astype(str)\n",
    "        else:\n",
    "            gdf_pudo_work['LOCALIDAD_PUDO'] = 'DESCONOCIDA'\n",
    "        \n",
    "        cols_pudo_final = [c for c in cols_common_ext if c in gdf_pudo_work.columns]\n",
    "        cols_partner_final = [c for c in cols_common_ext if c in gdf_partners_utm.columns]\n",
    "        \n",
    "        gdf_all_points = pd.concat([\n",
    "            gdf_pudo_work[cols_pudo_final],\n",
    "            gdf_partners_utm[cols_partner_final]\n",
    "        ], ignore_index=True)\n",
    "        gdf_all_points = gpd.GeoDataFrame(gdf_all_points, geometry='geometry', crs=gdf_pudo_work.crs)\n",
    "        print(f\"Total puntos a analizar (PUDOs + Partners): {len(gdf_all_points)}\")\n",
    "        \n",
    "        cols_mz_select = ['LOCALIDAD', 'COMUNA', 'COMUNA_NORM', 'geometry']\n",
    "        cols_mz_avail = [c for c in cols_mz_select if c in manzanas_work.columns]\n",
    "        if geom_col_work not in cols_mz_avail and geom_col_work in manzanas_work.columns:\n",
    "            cols_mz_avail.append(geom_col_work)\n",
    "        \n",
    "        if cols_mz_avail and not gdf_all_points.empty:\n",
    "            missing_localidad = gdf_all_points['LOCALIDAD_PUDO'] == 'DESCONOCIDA'\n",
    "            if missing_localidad.any():\n",
    "                points_for_join = gpd.GeoDataFrame(\n",
    "                    gdf_all_points.loc[missing_localidad, ['PUDO_ID', 'geometry']].copy(),\n",
    "                    geometry='geometry',\n",
    "                    crs=gdf_all_points.crs\n",
    "                )\n",
    "                manzanas_for_join = gpd.GeoDataFrame(\n",
    "                    manzanas_work[cols_mz_avail].copy(),\n",
    "                    geometry=geom_col_work,\n",
    "                    crs=manzanas_work.crs\n",
    "                )\n",
    "                nearest_localidad = gpd.sjoin_nearest(\n",
    "                    points_for_join,\n",
    "                    manzanas_for_join,\n",
    "                    how='left',\n",
    "                    max_distance=800\n",
    "                )\n",
    "                cols_merge = [c for c in ['PUDO_ID', 'LOCALIDAD', 'COMUNA'] if c in nearest_localidad.columns]\n",
    "                if cols_merge:\n",
    "                    for idx, row in nearest_localidad.iterrows():\n",
    "                        pid = row['PUDO_ID']\n",
    "                        mask = gdf_all_points['PUDO_ID'] == pid\n",
    "                        if 'LOCALIDAD' in row and pd.notna(row['LOCALIDAD']):\n",
    "                            gdf_all_points.loc[mask, 'LOCALIDAD_PUDO'] = row['LOCALIDAD']\n",
    "                        if 'COMUNA' in row and pd.notna(row['COMUNA']):\n",
    "                            gdf_all_points.loc[mask, 'COMUNA'] = row['COMUNA']\n",
    "                            gdf_all_points.loc[mask, 'COMUNA_NORM'] = normalize_text(row['COMUNA'])\n",
    "        \n",
    "        gdf_all_points['COMUNA'] = gdf_all_points['COMUNA'].fillna('').astype(str)\n",
    "        gdf_all_points['LOCALIDAD_PUDO'] = gdf_all_points['LOCALIDAD_PUDO'].fillna('DESCONOCIDA').astype(str)\n",
    "        \n",
    "        registros_pudo = []\n",
    "        \n",
    "        comunas_all = gdf_all_points['COMUNA_NORM'].fillna('').astype(str).unique()\n",
    "        total_comunas = len(comunas_all)\n",
    "        anchor_agency_map = gdf_all_points.set_index('PUDO_ID')['AGENCY_ID'].to_dict()\n",
    "        ofcn_map = gdf_all_points.set_index('PUDO_ID')['OFCN_DSC'].to_dict()\n",
    "        q_dao_map = gdf_all_points.set_index('PUDO_ID')['Q_DAO'].to_dict()\n",
    "        \n",
    "        for idx_c, comuna_norm in enumerate(comunas_all, start=1):\n",
    "            if idx_c % 20 == 0:\n",
    "                print(f\"   Procesando comuna {idx_c}/{total_comunas}: {comuna_norm}\")\n",
    "            points_comuna = gdf_all_points[gdf_all_points['COMUNA_NORM'] == comuna_norm].copy()\n",
    "            mz_comuna = manzanas_work[manzanas_work['COMUNA_NORM'] == comuna_norm][['MANZENT', 'TOTAL_PERS', geom_col_work]].copy()\n",
    "            mz_comuna = gpd.GeoDataFrame(mz_comuna, geometry=geom_col_work, crs=manzanas_work.crs)\n",
    "            if points_comuna.empty or mz_comuna.empty:\n",
    "                continue\n",
    "            \n",
    "            buffers = points_comuna[['PUDO_ID', 'COMUNA', 'COMUNA_NORM', 'LOCALIDAD_PUDO', 'AGENCY_ID']].copy()\n",
    "            buffers['center_geom'] = points_comuna.geometry # Guardar centro original\n",
    "            buffers['geometry'] = points_comuna.geometry.buffer(800)\n",
    "            buffers = gpd.GeoDataFrame(buffers, geometry='geometry', crs=points_comuna.crs)\n",
    "            \n",
    "            inter_all = gpd.overlay(\n",
    "                mz_comuna[['MANZENT', 'TOTAL_PERS', geom_col_work]],\n",
    "                buffers[['PUDO_ID', 'geometry']],\n",
    "                how='intersection'\n",
    "            )\n",
    "            if not inter_all.empty:\n",
    "                inter_all = gpd.GeoDataFrame(inter_all, geometry=inter_all.geometry, crs=mz_comuna.crs)\n",
    "                inter_all['area_inter'] = inter_all.geometry.area\n",
    "                inter_all['area_mz'] = inter_all['MANZENT'].map(manzanas_area_map).replace(0, 1.0)\n",
    "                inter_all['pob_piece'] = inter_all['TOTAL_PERS'] * (inter_all['area_inter'] / inter_all['area_mz'])\n",
    "                poblacion_total = inter_all.groupby('PUDO_ID')['pob_piece'].sum()\n",
    "                \n",
    "                geom_inter = inter_all.geometry.name\n",
    "                cover_counts = gpd.sjoin(\n",
    "                    inter_all[['PUDO_ID', 'MANZENT', 'pob_piece', geom_inter]],\n",
    "                    buffers[['PUDO_ID', 'geometry']],\n",
    "                    how='left',\n",
    "                    predicate='intersects'\n",
    "                )\n",
    "                cover_counts['covers'] = cover_counts.groupby(cover_counts.index)['PUDO_ID_right'].transform('nunique')\n",
    "                exclusivos = cover_counts[cover_counts['covers'] == 1]\n",
    "                poblacion_unica = exclusivos.groupby('PUDO_ID_left')['pob_piece'].sum() if not exclusivos.empty else pd.Series(dtype=float)\n",
    "            else:\n",
    "                poblacion_total = pd.Series(dtype=float)\n",
    "                poblacion_unica = pd.Series(dtype=float)\n",
    "            \n",
    "            sindex = buffers.sindex\n",
    "            vecinos_overlap = {}\n",
    "            cannibal_potential = {}\n",
    "            \n",
    "            for idx_buf, buf_row in buffers.iterrows():\n",
    "                vecinos_idx = sindex.query(buf_row.geometry, predicate='intersects')\n",
    "                vecinos_overlap[buf_row.PUDO_ID] = max(len(vecinos_idx) - 1, 0)\n",
    "                \n",
    "                total_robbed = 0.0\n",
    "                vecinos_geoms = buffers.iloc[vecinos_idx]\n",
    "                \n",
    "                for _, vecino in vecinos_geoms.iterrows():\n",
    "                    if vecino.PUDO_ID == buf_row.PUDO_ID:\n",
    "                        continue\n",
    "                    intersection = buf_row.geometry.intersection(vecino.geometry)\n",
    "                    if not intersection.is_empty:\n",
    "                        area_inter = intersection.area\n",
    "                        area_vecino = vecino.geometry.area\n",
    "                        if area_vecino > 0:\n",
    "                            pct_overlap = area_inter / area_vecino\n",
    "                            robbed = q_dao_map.get(vecino.PUDO_ID, 0) * pct_overlap\n",
    "                            total_robbed += robbed\n",
    "                cannibal_potential[buf_row.PUDO_ID] = total_robbed\n",
    "            \n",
    "            q_tipo = {}\n",
    "            q_vecinos_reales = {}\n",
    "            \n",
    "            # --- CONTEO DE PUDOS AZULES/COPEC ---\n",
    "            if not gdf_ag_utm.empty:\n",
    "                join_ag = gpd.sjoin(\n",
    "                    buffers[['PUDO_ID', 'AGENCY_ID', 'geometry']],\n",
    "                    gdf_ag_utm[['agencyid', 'tipo_punto_std', 'geometry']],\n",
    "                    how='inner',\n",
    "                    predicate='intersects'\n",
    "                )\n",
    "                if not join_ag.empty:\n",
    "                    join_ag = join_ag.rename(columns={'PUDO_ID_left': 'PUDO_ID'})\n",
    "                    join_ag['anchor_agency'] = join_ag['PUDO_ID'].map(anchor_agency_map)\n",
    "                    join_ag = join_ag[join_ag['agencyid'] != join_ag['anchor_agency']]\n",
    "                    grouped = join_ag.groupby('PUDO_ID')['tipo_punto_std'].value_counts()\n",
    "                    for (pid, tipo), val in grouped.items():\n",
    "                        if pid not in q_tipo:\n",
    "                            q_tipo[pid] = {'blue': 0, 'copec': 0, 'partner': 0}\n",
    "                        if tipo == 'blue':\n",
    "                            q_tipo[pid]['blue'] += int(val)\n",
    "                        elif tipo == 'copec':\n",
    "                            q_tipo[pid]['copec'] += int(val)\n",
    "                        else:\n",
    "                            q_tipo[pid]['partner'] += int(val)\n",
    "            \n",
    "            # --- CONTEO DE PARTNERS (CON AJUSTE -1) ---\n",
    "            if not gdf_partners_utm.empty:\n",
    "                ag_partners = gdf_partners_utm.copy()\n",
    "                ag_partners['agencyid'] = ag_partners['PUDO_ID']\n",
    "                join_partners = gpd.sjoin(\n",
    "                    ag_partners[['agencyid', 'lat_round', 'lon_round', 'geometry']],\n",
    "                    buffers[['PUDO_ID', 'center_geom', 'geometry']],\n",
    "                    how='inner',\n",
    "                    predicate='intersects'\n",
    "                )\n",
    "                if not join_partners.empty:\n",
    "                    join_partners = join_partners.rename(columns={'PUDO_ID_right': 'PUDO_ID'})\n",
    "                    \n",
    "                    # 1. Filtro por ID (Evitar auto-referencia)\n",
    "                    join_partners['agencyid'] = join_partners['agencyid'].astype(str)\n",
    "                    join_partners['PUDO_ID_str'] = join_partners['PUDO_ID'].astype(str)\n",
    "                    join_partners = join_partners[join_partners['agencyid'] != join_partners['PUDO_ID_str']]\n",
    "                    \n",
    "                    # 2. Filtro de \"Hijos\" de Agencia\n",
    "                    join_partners['anchor_agency'] = join_partners['PUDO_ID'].map(anchor_agency_map)\n",
    "                    join_partners = join_partners[join_partners['agencyid'] != join_partners['anchor_agency'].astype(str)]\n",
    "                    \n",
    "                    # 3. Triple check: Distancia > 1m para evitar duplicados \"fantasma\"\n",
    "                    join_partners['dist_check'] = join_partners.geometry.distance(join_partners['center_geom'])\n",
    "                    join_partners = join_partners[join_partners['dist_check'] > 1.0]\n",
    "\n",
    "                    # Deduplicación final\n",
    "                    join_partners = join_partners.drop_duplicates(subset=['PUDO_ID', 'lat_round', 'lon_round'])\n",
    "                    partner_counts = join_partners.groupby('PUDO_ID').size()\n",
    "                    \n",
    "                    for pid, val in partner_counts.items():\n",
    "                        if pid not in q_tipo:\n",
    "                            q_tipo[pid] = {'blue': 0, 'copec': 0, 'partner': 0}\n",
    "                        \n",
    "                        # AJUSTE SOLICITADO: Restar 1 al conteo de partners si es mayor a 0\n",
    "                        final_val = int(val)\n",
    "                        if final_val > 0:\n",
    "                            final_val -= 1\n",
    "                        \n",
    "                        q_tipo[pid]['partner'] = final_val\n",
    "            \n",
    "            for pid, counts in q_tipo.items():\n",
    "                total_neighbors = counts.get('blue', 0) + counts.get('copec', 0) + counts.get('partner', 0)\n",
    "                q_vecinos_reales[pid] = total_neighbors\n",
    "            \n",
    "            for _, buf_row in buffers.iterrows():\n",
    "                pid = buf_row.PUDO_ID\n",
    "                point_info = gdf_all_points[gdf_all_points['PUDO_ID'] == pid].iloc[0]\n",
    "                lat = point_info.get('lat')\n",
    "                lon = point_info.get('lon')\n",
    "                counts_tipo = q_tipo.get(pid, {'blue': 0, 'copec': 0, 'partner': 0})\n",
    "                ofcn_val = ofcn_map.get(pid, '')\n",
    "                q_dao_val = q_dao_map.get(pid, 0)\n",
    "                potencial_robo = cannibal_potential.get(pid, 0.0)\n",
    "                \n",
    "                registros_pudo.append({\n",
    "                    'PUDO_ID': pid,\n",
    "                    'AGENCY_ID': anchor_agency_map.get(pid),\n",
    "                    'OFCN_DSC': ofcn_val,\n",
    "                    'Q_DAO_PROPIO': q_dao_val,\n",
    "                    'POTENCIAL_ROBO_Q': round(potencial_robo, 2),\n",
    "                    'COMUNA': buf_row.COMUNA,\n",
    "                    'LOCALIDAD': buf_row.LOCALIDAD_PUDO,\n",
    "                    'LAT': lat,\n",
    "                    'LON': lon,\n",
    "                    'POBLACION_CUBIERTA_PUDO': int(round(poblacion_total.get(pid, 0))),\n",
    "                    'POBLACION_UNICA_PUDO': int(round(poblacion_unica.get(pid, 0))),\n",
    "                    'PUDOS_OVERLAP_BUFFERS': vecinos_overlap.get(pid, 0),\n",
    "                    'q_vecinos_reales': q_vecinos_reales.get(pid, 0),\n",
    "                    'q_blue': counts_tipo.get('blue', 0),\n",
    "                    'q_copec': counts_tipo.get('copec', 0),\n",
    "                    'q_partner': counts_tipo.get('partner', 0),\n",
    "                    'TIPO_PUNTO': point_info.get('TIPO_PUNTO_PUDO', ''),\n",
    "                    'IS_PARTNER': point_info.get('IS_PARTNER', False)\n",
    "                })\n",
    "        \n",
    "        if registros_pudo:\n",
    "            df_reporte_pudo = pd.DataFrame(registros_pudo)\n",
    "            filename_pudo = 'Cobertura_Por_PUDO_y_Partners.xlsx'\n",
    "            try:\n",
    "                df_reporte_pudo.to_excel(filename_pudo, index=False)\n",
    "            except PermissionError:\n",
    "                alt_name = 'Cobertura_Por_PUDO_y_Partners_alt.xlsx'\n",
    "                print(f\"Aviso: '{filename_pudo}' está bloqueado. Guardando en '{alt_name}'\")\n",
    "                df_reporte_pudo.to_excel(alt_name, index=False)\n",
    "                filename_pudo = alt_name\n",
    "            print(f\"\\n✅ Archivo generado: {filename_pudo}\")\n",
    "            print(f\"   Total registros: {len(df_reporte_pudo):,}\")\n",
    "            print(f\"   - PUDOs: {(~df_reporte_pudo['IS_PARTNER']).sum():,}\")\n",
    "            print(f\"   - Partners: {df_reporte_pudo['IS_PARTNER'].sum():,}\")\n",
    "            print(\"\\nEjemplo de datos:\")\n",
    "            print(df_reporte_pudo.head(10))\n",
    "        else:\n",
    "            print(\"No se generaron registros para el reporte de PUDOs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3b0983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paso 7: Análisis de Oportunidades de Expansión ---\n",
      "Reporte de Oportunidades generado: Oportunidades_Expansion_PUDOs.xlsx\n",
      "\n",
      "=== TOP 10 LUGARES PARA 'MOVER LA AGUJA' (Mayor Población Sin Atender) ===\n",
      "       COMUNA                                LOCALIDAD  POBLACION_TOTAL  POBLACION_CUBIERTA  POBLACION_SIN_CUBRIR  PORCENTAJE_COBERTURA  CANTIDAD_PUDOS_LOCALIDAD                        TIPO_OPORTUNIDAD\n",
      "  ANTOFAGASTA                              ANTOFAGASTA           387247              264765                122482                0.6837                        39  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      " VIÑA DEL MAR                          GRAN VALPARAÍSO           330109              225794                104315                0.6840                        60  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      "   VALPARAÍSO                          GRAN VALPARAÍSO           221330              123049                 98281                0.5560                        34  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      " SAN BERNARDO                            GRAN SANTIAGO           290334              195504                 94830                0.6734                        31  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      "  PUENTE ALTO                            GRAN SANTIAGO           560695              470551                 90144                0.8392                        72          MANTENIMIENTO (Cobertura Alta)\n",
      "       CALAMA                                   CALAMA           159918               73928                 85990                0.4623                        10 DENSIFICACIÓN CRÍTICA (Cobertura < 50%)\n",
      "ALTO HOSPICIO                  IQUIQUE - ALTO HOSPICIO           134762               51991                 82771                0.3858                        10 DENSIFICACIÓN CRÍTICA (Cobertura < 50%)\n",
      "       TEMUCO                 TEMUCO - PADRE LAS CASAS           227403              147641                 79762                0.6492                        29  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      "      COPIAPÓ                                  COPIAPÓ           160462               89721                 70741                0.5591                        18  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      "     RANCAGUA RANCAGUA – MACHALÍ – GULTRO – LOS LIRIOS           242421              177647                 64774                0.7328                        41  DENSIFICACIÓN MEDIA (Mejorar Servicio)\n",
      "\n",
      "=== TOP 5 OPORTUNIDADES 'GREENFIELD' (Lugares con 0 PUDOs y mucha gente) ===\n",
      "         COMUNA                LOCALIDAD  POBLACION_TOTAL  POBLACION_CUBIERTA  POBLACION_SIN_CUBRIR  PORCENTAJE_COBERTURA  CANTIDAD_PUDOS_LOCALIDAD       TIPO_OPORTUNIDAD\n",
      "PADRE LAS CASAS TEMUCO - PADRE LAS CASAS            41379                 128                 41251                0.0031                         0 EXPANSIÓN (Zona Nueva)\n",
      "     LOS ÁLAMOS               LOS ÁLAMOS             8331                   1                  8330                0.0001                         0 EXPANSIÓN (Zona Nueva)\n",
      "           BUIN                   VILUCO             6334                   0                  6334                0.0000                         0 EXPANSIÓN (Zona Nueva)\n",
      "   MONTE PATRIA             MONTE PATRIA             6251                   0                  6251                0.0000                         0 EXPANSIÓN (Zona Nueva)\n",
      "      PERALILLO                PERALILLO             6223                   0                  6223                0.0000                         0 EXPANSIÓN (Zona Nueva)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. ANÁLISIS DE OPORTUNIDADES (DONDE MOVER LA AGUJA)\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 7: Análisis de Oportunidades de Expansión ---\")\n",
    "\n",
    "# Contexto: Buscamos maximizar el impacto. \n",
    "# \"Mover la aguja\" significa capturar la mayor cantidad de población nueva con el menor esfuerzo (nuevos puntos).\n",
    "# Estrategia: Identificar Entidades (Barrios/Aldeas/Ciudades) con alta población NO cubierta.\n",
    "\n",
    "if 'df_resumen' in locals() and not df_resumen.empty:\n",
    "    \n",
    "    # 1. Calcular el GAP (Población Sin Cubrir)\n",
    "    df_oportunidades = df_resumen.copy()\n",
    "    df_oportunidades['POBLACION_SIN_CUBRIR'] = df_oportunidades['POBLACION_TOTAL'] - df_oportunidades['POBLACION_CUBIERTA']\n",
    "    \n",
    "    # 2. Clasificar el tipo de oportunidad\n",
    "    def clasificar_oportunidad(row):\n",
    "        if row['CANTIDAD_PUDOS_LOCALIDAD'] == 0:\n",
    "            return \"EXPANSIÓN (Zona Nueva)\"\n",
    "        elif row['PORCENTAJE_COBERTURA'] < 0.5:\n",
    "            return \"DENSIFICACIÓN CRÍTICA (Cobertura < 50%)\"\n",
    "        elif row['PORCENTAJE_COBERTURA'] < 0.8:\n",
    "            return \"DENSIFICACIÓN MEDIA (Mejorar Servicio)\"\n",
    "        else:\n",
    "            return \"MANTENIMIENTO (Cobertura Alta)\"\n",
    "\n",
    "    df_oportunidades['TIPO_OPORTUNIDAD'] = df_oportunidades.apply(clasificar_oportunidad, axis=1)\n",
    "    \n",
    "    # 3. Ranking de Impacto\n",
    "    # Ordenamos por la cantidad absoluta de personas que hoy NO atendemos\n",
    "    df_ranking = df_oportunidades.sort_values(by='POBLACION_SIN_CUBRIR', ascending=False)\n",
    "    \n",
    "    # Filtramos casos triviales (ej. donde falta muy poca gente)\n",
    "    df_ranking = df_ranking[df_ranking['POBLACION_SIN_CUBRIR'] > 100]\n",
    "\n",
    "    # 4. Generar Reporte Estratégico\n",
    "    cols_estrategia = [\n",
    "        'COMUNA', 'LOCALIDAD',\n",
    "        'POBLACION_TOTAL', 'POBLACION_CUBIERTA', 'POBLACION_SIN_CUBRIR', \n",
    "        'PORCENTAJE_COBERTURA', 'CANTIDAD_PUDOS_LOCALIDAD', 'TIPO_OPORTUNIDAD'\n",
    "    ]\n",
    "    \n",
    "    df_estrategia = df_ranking[cols_estrategia]\n",
    "    \n",
    "    # Guardar\n",
    "    filename_opp = 'Oportunidades_Expansion_PUDOs.xlsx'\n",
    "    df_estrategia.to_excel(filename_opp, index=False)\n",
    "    print(f\"Reporte de Oportunidades generado: {filename_opp}\")\n",
    "    \n",
    "    # --- VISUALIZACIÓN DE INSIGHTS ---\n",
    "    print(\"\\n=== TOP 10 LUGARES PARA 'MOVER LA AGUJA' (Mayor Población Sin Atender) ===\")\n",
    "    print(df_estrategia.head(10).to_string(index=False))\n",
    "    \n",
    "    print(\"\\n=== TOP 5 OPORTUNIDADES 'GREENFIELD' (Lugares con 0 PUDOs y mucha gente) ===\")\n",
    "    greenfield = df_estrategia[df_estrategia['CANTIDAD_PUDOS_LOCALIDAD'] == 0]\n",
    "    print(greenfield.head(5).to_string(index=False))\n",
    "\n",
    "else:\n",
    "    print(\"Error: No se encontró 'df_resumen'. Ejecuta el paso 6 primero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26dd5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paso 8: Generando Mapa Interactivo Nacional ---\n",
      "Preparando datos geoespaciales...\n",
      "Manzanas con población: 191,061\n",
      "Cargando datos de Forecast (Capacidad)...\n",
      "Comunas con datos de Forecast: 312\n",
      "Creando mapa base...\n",
      "Generando HeatMap de población sin cobertura...\n",
      "   Puntos en heatmap: 32,081\n",
      "   Rango de pesos: 0.61 - 1.00\n",
      "Generando HeatMap de población cubierta...\n",
      "Agregando marcadores de PUDOs...\n",
      "Agregando marcadores de Partners...\n",
      "   659 marcadores de partners agregados\n",
      "Agregando marcadores de Forecast (Capacidad)...\n",
      "   312 marcadores de forecast agregados\n",
      "Agregando TOP oportunidades de expansión...\n",
      "Identificando zonas sobreservidas...\n",
      "Agregando controles...\n",
      "Agregando barra de búsqueda...\n",
      "   Indexando Localidades (Comuna + Localidad) para el buscador...\n",
      "   Total de entradas en el buscador: 9299\n",
      "   Barra de búsqueda agregada (Comunas y Localidades).\n",
      "\n",
      "✅ Mapa interactivo generado: Mapa_Cobertura_Nacional_Blue.html\n",
      "   Tamaño aproximado del archivo: 32,081 puntos de calor\n",
      "\n",
      "Instrucciones: abra el HTML, use panel de capas y haga zoom para detalle.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 8. MAPA INTERACTIVO DE COBERTURA NACIONAL\n",
    "# ==========================================\n",
    "\n",
    "print(\"--- Paso 8: Generando Mapa Interactivo Nacional ---\")\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster, MiniMap, Search\n",
    "from branca.colormap import LinearColormap\n",
    "import numpy as np\n",
    "import pandas as pd # Ensure pandas is available\n",
    "\n",
    "# ==========================================\n",
    "# A. PREPARACIÓN DE DATOS PARA EL MAPA\n",
    "# ==========================================\n",
    "\n",
    "print(\"Preparando datos geoespaciales...\")\n",
    "\n",
    "# 1. Convertir manzanas a EPSG:4326 (lat/lon) para Folium\n",
    "manzanas_wgs84 = manzanas_utm.to_crs(epsg=4326)\n",
    "\n",
    "# 2. Calcular centroides de cada manzana\n",
    "manzanas_wgs84['centroid'] = manzanas_wgs84.geometry.centroid\n",
    "manzanas_wgs84['lat'] = manzanas_wgs84['centroid'].y\n",
    "manzanas_wgs84['lon'] = manzanas_wgs84['centroid'].x\n",
    "\n",
    "# 3. Unir con métricas calculadas (df_final tiene pct_cobertura)\n",
    "# Usar MANZENT como key\n",
    "df_map = manzanas_wgs84[['MANZENT', 'COMUNA', 'ENTIDAD', 'LOCALIDAD', 'TOTAL_PERS', 'lat', 'lon']].copy()\n",
    "df_map = df_map.merge(\n",
    "    df_final[['MANZENT', 'pct_cobertura', 'pob_cubierta', 'pudos_en_manzana']],\n",
    "    on='MANZENT',\n",
    "    how='left'\n",
    " )\n",
    "df_map['pct_cobertura'] = df_map['pct_cobertura'].fillna(0)\n",
    "df_map['pob_cubierta'] = df_map['pob_cubierta'].fillna(0)\n",
    "df_map['pudos_en_manzana'] = df_map['pudos_en_manzana'].fillna(0)\n",
    "\n",
    "# 4. Calcular población sin cubrir\n",
    "df_map['pob_sin_cubrir'] = df_map['TOTAL_PERS'] - df_map['pob_cubierta']\n",
    "df_map['pob_sin_cubrir'] = df_map['pob_sin_cubrir'].clip(lower=0)\n",
    "\n",
    "# 5. Filtrar manzanas con población > 0 para el heatmap\n",
    "df_map_poblado = df_map[df_map['TOTAL_PERS'] > 0].copy()\n",
    "\n",
    "print(f\"Manzanas con población: {len(df_map_poblado):,}\")\n",
    "\n",
    "# ==========================================\n",
    "# A.1. CARGA DE DATOS DE FORECAST\n",
    "# ==========================================\n",
    "\n",
    "print(\"Cargando datos de Forecast (Capacidad)...\")\n",
    "\n",
    "try:\n",
    "    df_forecast = pd.read_excel('data/FCST intermedio paara heatmap.xlsx')\n",
    "    \n",
    "    # Normalizar nombre de comuna para hacer join\n",
    "    df_forecast['COMUNA_NORM'] = df_forecast['comuna'].apply(normalize_text)\n",
    "\n",
    "    # Crear dataframe de coordenadas por comuna (promedio de centroides)\n",
    "    df_coords_comuna = df_map.groupby('COMUNA').agg({\n",
    "        'lat': 'mean',\n",
    "        'lon': 'mean'\n",
    "    }).reset_index()\n",
    "    df_coords_comuna['COMUNA_NORM'] = df_coords_comuna['COMUNA'].apply(normalize_text)\n",
    "    \n",
    "    # Join forecast con coordenadas\n",
    "    df_forecast_geo = df_forecast.merge(\n",
    "        df_coords_comuna[['COMUNA_NORM', 'lat', 'lon']],\n",
    "        on='COMUNA_NORM',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(f\"Comunas con datos de Forecast: {len(df_forecast_geo)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error cargando datos de Forecast: {e}\")\n",
    "    df_forecast_geo = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# B. CREAR MAPA BASE\n",
    "# ==========================================\n",
    "\n",
    "print(\"Creando mapa base...\")\n",
    "\n",
    "# Centro de Chile (aproximado)\n",
    "chile_center = [-33.45, -70.65]\n",
    "\n",
    "mapa = folium.Map(\n",
    "    location=chile_center,\n",
    "    zoom_start=6,\n",
    "    tiles=None,\n",
    "    control_scale=True\n",
    " )\n",
    "\n",
    "folium.TileLayer('cartodbpositron', name='Mapa Claro').add_to(mapa)\n",
    "folium.TileLayer('cartodbdark_matter', name='Mapa Oscuro').add_to(mapa)\n",
    "folium.TileLayer('OpenStreetMap', name='OpenStreetMap').add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# C. CAPA 1: HEATMAP DE POBLACIÓN SIN COBERTURA\n",
    "# ==========================================\n",
    "\n",
    "print(\"Generando HeatMap de población sin cobertura...\")\n",
    "\n",
    "df_sin_cob = df_map_poblado[df_map_poblado['pob_sin_cubrir'] > 0].copy()\n",
    "# Umbral más bajo pero aún filtrando rural disperso\n",
    "df_sin_cob = df_sin_cob[df_sin_cob['pob_sin_cubrir'] >= 60]\n",
    "\n",
    "df_sin_cob['log_pob'] = np.log10(df_sin_cob['pob_sin_cubrir'].clip(lower=1))\n",
    "\n",
    "# Normalizar con percentil 99 para mantener ciudades altas visibles\n",
    "q99 = df_sin_cob['log_pob'].quantile(0.99)\n",
    "scale = q99 if q99 > 0 else 1.0\n",
    "df_sin_cob['peso_norm'] = (df_sin_cob['log_pob'] / scale).clip(0, 1.0)\n",
    "\n",
    "# Filtrar pesos bajos (menos transparencia)\n",
    "df_sin_cob = df_sin_cob[df_sin_cob['peso_norm'] > 0.12]\n",
    "\n",
    "heat_data_sin_cobertura = df_sin_cob[['lat', 'lon', 'peso_norm']].values.tolist()\n",
    "\n",
    "print(f\"   Puntos en heatmap: {len(heat_data_sin_cobertura):,}\")\n",
    "print(f\"   Rango de pesos: {df_sin_cob['peso_norm'].min():.2f} - {df_sin_cob['peso_norm'].max():.2f}\")\n",
    "\n",
    "heatmap_sin_cobertura = HeatMap(\n",
    "    heat_data_sin_cobertura,\n",
    "    name='Población SIN Cobertura (Oportunidad)',\n",
    "    min_opacity=0.05,\n",
    "    max_zoom=18,\n",
    "    radius=12,\n",
    "    blur=8,\n",
    "    gradient={\n",
    "        0.0: 'transparent',\n",
    "        0.12: 'transparent',\n",
    "        0.2: 'yellow',\n",
    "        0.4: 'orange',\n",
    "        0.65: 'red',\n",
    "        0.85: 'purple',\n",
    "        1.0: 'darkred'\n",
    "    }\n",
    " )\n",
    "heatmap_sin_cobertura.add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# D. CAPA 2: HEATMAP DE POBLACIÓN CON COBERTURA (VERDE)\n",
    "# ==========================================\n",
    "\n",
    "print(\"Generando HeatMap de población cubierta...\")\n",
    "\n",
    "df_cubierta = df_map_poblado[df_map_poblado['pob_cubierta'] > 0].copy()\n",
    "# Reestablecer escala original (solo verde) sin los cortes agresivos\n",
    "df_cubierta = df_cubierta[df_cubierta['pob_cubierta'] >= 20]\n",
    "\n",
    "df_cubierta['log_pob'] = np.log10(df_cubierta['pob_cubierta'].clip(lower=1))\n",
    "q99_c = df_cubierta['log_pob'].quantile(0.99)\n",
    "scale_c = q99_c if q99_c > 0 else 1.0\n",
    "df_cubierta['peso_norm'] = (df_cubierta['log_pob'] / scale_c).clip(0, 1.0)\n",
    "df_cubierta = df_cubierta[df_cubierta['peso_norm'] > 0.05]\n",
    "\n",
    "heat_data_cubierta = df_cubierta[['lat', 'lon', 'peso_norm']].values.tolist()\n",
    "\n",
    "heatmap_cubierta = HeatMap(\n",
    "    heat_data_cubierta,\n",
    "    name='Población CON Cobertura',\n",
    "    min_opacity=0.2,\n",
    "    max_zoom=18,\n",
    "    radius=12,\n",
    "    blur=8,\n",
    "    gradient={\n",
    "        0.0: 'palegreen',\n",
    "        0.2: 'lightgreen',\n",
    "        0.4: 'green',\n",
    "        0.7: 'darkgreen',\n",
    "        1.0: 'darkslategray'\n",
    "    },\n",
    "    show=False\n",
    " )\n",
    "heatmap_cubierta.add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# E. CAPA 3: MARCADORES DE PUDOs (TIENDAS)\n",
    "# ==========================================\n",
    "\n",
    "print(\"Agregando marcadores de PUDOs...\")\n",
    "\n",
    "pudo_cluster = MarkerCluster(\n",
    "    name='PUDOs Activos',\n",
    "    show=True,\n",
    "    options={\n",
    "        'disableClusteringAtZoom': 14,\n",
    "        'spiderfyOnMaxZoom': True\n",
    "    }\n",
    " )\n",
    "\n",
    "gdf_pudo_wgs84 = gdf_PUDO.to_crs(epsg=4326)\n",
    "\n",
    "# Asegurar que las columnas numéricas sean float para evitar errores de formato\n",
    "cols_numeric = [\n",
    "    'q dao avg mes', \n",
    "    'q dao max mes', \n",
    "    'avg_packages_daily', \n",
    "    'peak_packages_weekly',\n",
    "    'sobrecapacidad HOY - capacidad actual',\n",
    "    'sobrecapacidad fcst peak - capacidad proyectada',\n",
    "    'share del punto en la comuna'\n",
    "]\n",
    "\n",
    "for col in cols_numeric:\n",
    "    if col in gdf_pudo_wgs84.columns:\n",
    "        gdf_pudo_wgs84[col] = pd.to_numeric(gdf_pudo_wgs84[col], errors='coerce').fillna(0)\n",
    "\n",
    "for idx, row in gdf_pudo_wgs84.iterrows():\n",
    "    popup_html = f'''\n",
    "    <div style='width:280px; font-family: Arial, sans-serif;'>\n",
    "        <h4 style='margin:0 0 10px 0; color:#0066cc;'>{row.get('ofcn_dsc', 'PUDO')}</h4>\n",
    "        <div style='font-size:11px; margin-bottom:5px;'><b>Comuna:</b> {row.get('cmns_nmb', 'N/A')}</div>\n",
    "        <table style='width:100%; font-size:11px; border-collapse: collapse;'>\n",
    "            <tr style='background-color:#f0f0f0;'>\n",
    "                <td style='padding:4px;'><b>Tipo de Punto:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('tipo_punto', 'N/A')}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style='padding:4px;'><b>Apto Locker:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('apto_locker', 'N/A')}</td>\n",
    "            </tr>\n",
    "            <tr style='background-color:#f0f0f0;'>\n",
    "                <td style='padding:4px;'><b>Tiene Locker:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('tiene_locker', 'N/A')}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style='padding:4px;'><b>Q DAO Avg Mes:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('q dao avg mes', 0):,.0f}</td>\n",
    "            </tr>\n",
    "            <tr style='background-color:#f0f0f0;'>\n",
    "                <td style='padding:4px;'><b>Q DAO Max Mes:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('q dao max mes', 0):,.0f}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style='padding:4px;'><b>Avg Paquetes Diarios:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('avg_packages_daily', 0):,.1f}</td>\n",
    "            </tr>\n",
    "            <tr style='background-color:#f0f0f0;'>\n",
    "                <td style='padding:4px;'><b>Peak Paquetes Semanal:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('peak_packages_weekly', 0):,.0f}</td>\n",
    "            </tr>\n",
    "             <tr>\n",
    "                <td style='padding:4px;'><b>Sobrecapacidad Actual:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('sobrecapacidad HOY - capacidad actual', 0):,.0f}</td>\n",
    "            </tr>\n",
    "            <tr style='background-color:#f0f0f0;'>\n",
    "                <td style='padding:4px;'><b>Sobrecapacidad Proyectada:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('sobrecapacidad fcst peak - capacidad proyectada', 0):,.0f}</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style='padding:4px;'><b>Share en Comuna:</b></td>\n",
    "                <td style='padding:4px;'>{row.get('share del punto en la comuna', 0)*100:.1f}%</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    '''\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        popup=folium.Popup(popup_html, max_width=300),\n",
    "        icon=folium.Icon(color='blue', icon='store', prefix='fa')\n",
    "    ).add_to(pudo_cluster)\n",
    "\n",
    "pudo_cluster.add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# E.1. CAPA 3.1: PARTNERS DESDE CSV\n",
    "# ==========================================\n",
    "\n",
    "print(\"Agregando marcadores de Partners...\")\n",
    "\n",
    "try:\n",
    "    df_partners = pd.read_csv('data/partners_mapa.csv')\n",
    "    \n",
    "    # Crear FeatureGroup para partners\n",
    "    fg_partners = folium.FeatureGroup(name='Partners', show=False)\n",
    "    \n",
    "    for idx, row in df_partners.iterrows():\n",
    "        partner_name = row.get('Partner/Tipo', 'Partner')\n",
    "        lat = row.get('lat')\n",
    "        lon = row.get('lon')\n",
    "        \n",
    "        if pd.notna(lat) and pd.notna(lon):\n",
    "            folium.Marker(\n",
    "                location=[lat, lon],\n",
    "                popup=f\"<b>{partner_name}</b>\",\n",
    "                icon=folium.Icon(color='green', icon='shopping-cart', prefix='fa')\n",
    "            ).add_to(fg_partners)\n",
    "    \n",
    "    fg_partners.add_to(mapa)\n",
    "    print(f\"   {len(df_partners)} marcadores de partners agregados\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error cargando partners: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# E.2. CAPA 3.5: FORECAST DE CAPACIDAD POR COMUNA\n",
    "# ==========================================\n",
    "\n",
    "print(\"Agregando marcadores de Forecast (Capacidad)...\")\n",
    "\n",
    "if not df_forecast_geo.empty:\n",
    "    fg_forecast = folium.FeatureGroup(name='Forecast Capacidad Semanal', show=False)\n",
    "    \n",
    "    for idx, row in df_forecast_geo.iterrows():\n",
    "        # Determinar color según Diferencia FCST Peak vs Capacidad Proyectada\n",
    "        dif_fcst_peak = row.get('Diferencia FCST Peak vs Capacidad proyectada', 0)\n",
    "        \n",
    "        if dif_fcst_peak < -400:\n",
    "            pin_color = 'darkpurple'\n",
    "            icon_name = 'battery-empty'\n",
    "        elif dif_fcst_peak < -200:\n",
    "            pin_color = 'red'\n",
    "            icon_name = 'exclamation-triangle'\n",
    "        elif dif_fcst_peak < -100:\n",
    "            pin_color = 'orange'\n",
    "            icon_name = 'warning'\n",
    "        else:  # Between -100 and positive\n",
    "            pin_color = 'green'\n",
    "            icon_name = 'check-circle'\n",
    "        \n",
    "        # Construir popup con toda la información\n",
    "        popup_html = f\"\"\"\n",
    "        <div style='width:280px; font-family: Arial, sans-serif;'>\n",
    "            <h4 style='margin:0 0 10px 0; color:#0066cc;'>{row['comuna']}</h4>\n",
    "            <table style='width:100%; font-size:11px; border-collapse: collapse;'>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>Ranking:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Ranking', 'N/A')}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style='padding:4px;'><b>Capacidad Semanal:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Capacidad Semanal', 0):,.0f}</td>\n",
    "                </tr>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>Capacidad Proyectada 10%:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Capacidad Proyectada 10%', 0):,.0f}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style='padding:4px;'><b>OS Week FCST Valle:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('OS Week FCST Valle', 0):,.1f}</td>\n",
    "                </tr>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>OS Week FCST Peak:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('OS Week FCST Peak', 0):,.0f}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style='padding:4px;'><b>Total Agencias:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Total Agencias', 0)}</td>\n",
    "                </tr>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>#Agencias Sobrecapacidad:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('#Agencias Sobrecapacidad', 0)}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style='padding:4px;'><b>% Sobrecapacidad:</b></td>\n",
    "                    <td style='padding:4px; font-weight:bold;'>\n",
    "                        {row.get('% Sobrecapacidad', 0)*100:.1f}%\n",
    "                    </td>\n",
    "                </tr>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>% Capacidad Peak:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('%Capacidad Peak', 0)*100:.1f}%</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style='padding:4px;'><b>Dif. FCST Valle vs Cap:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Diferencia FCST Valle vs Capacidad actual', 0):,.0f}</td>\n",
    "                </tr>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>Dif. FCST Peak vs Cap Proy:</b></td>\n",
    "                    <td style='padding:4px; font-weight:bold; color:{\"purple\" if dif_fcst_peak < -400 else \"red\" if dif_fcst_peak < -200 else \"orange\" if dif_fcst_peak < -100 else \"green\"};'>\n",
    "                        {dif_fcst_peak:,.0f}\n",
    "                    </td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style='padding:4px;'><b>Q puntos óptimo valle:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Q puntos optimizado valle', 0)}</td>\n",
    "                </tr>\n",
    "                <tr style='background-color:#f0f0f0;'>\n",
    "                    <td style='padding:4px;'><b>Q puntos óptimo peak:</b></td>\n",
    "                    <td style='padding:4px;'>{row.get('Q puntos optimizado peak', 0)}</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        folium.Marker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            popup=folium.Popup(popup_html, max_width=300),\n",
    "            icon=folium.Icon(color=pin_color, icon=icon_name, prefix='fa')\n",
    "        ).add_to(fg_forecast)\n",
    "    \n",
    "    fg_forecast.add_to(mapa)\n",
    "    print(f\"   {len(df_forecast_geo)} marcadores de forecast agregados\")\n",
    "else:\n",
    "    print(\"   No se pudieron agregar marcadores de forecast\")\n",
    "\n",
    "# ==========================================\n",
    "# F. CAPA 4: TOP OPORTUNIDADES (Círculos grandes)\n",
    "# ==========================================\n",
    "\n",
    "print(\"Agregando TOP oportunidades de expansión...\")\n",
    "\n",
    "if 'df_estrategia' in locals() and not df_estrategia.empty:\n",
    "    fg_oportunidades = folium.FeatureGroup(name='TOP Oportunidades Expansión', show=False)\n",
    "    top_50 = df_estrategia.head(50)\n",
    "\n",
    "    for idx, row in top_50.iterrows():\n",
    "        # Buscar coordenadas por Comuna y Localidad (MATCH MÁS ESTRICTO)\n",
    "        mask = (\n",
    "            (df_map['LOCALIDAD'] == row['LOCALIDAD']) &\n",
    "            (df_map['COMUNA'] == row['COMUNA'])\n",
    "        )\n",
    "        subset = df_map[mask]\n",
    "        \n",
    "        if not subset.empty:\n",
    "            lat_mean = subset['lat'].mean()\n",
    "            lon_mean = subset['lon'].mean()\n",
    "            radius = min(max(row['POBLACION_SIN_CUBRIR'] / 100, 500), 5000)\n",
    "            if row['CANTIDAD_PUDOS_LOCALIDAD'] == 0:\n",
    "                color = 'red'\n",
    "                tipo = 'NUEVA ZONA'\n",
    "            elif row['PORCENTAJE_COBERTURA'] < 0.5:\n",
    "                color = 'orange'\n",
    "                tipo = 'CRITICO'\n",
    "            else:\n",
    "                color = 'yellow'\n",
    "                tipo = 'MEJORAR'\n",
    "            popup_html = f\"\"\"\n",
    "            <div style='width:200px'>\n",
    "                <h4>{row['LOCALIDAD']}</h4>\n",
    "                <b>Comuna:</b> {row['COMUNA']}<br>\n",
    "                <b>Población Total:</b> {row['POBLACION_TOTAL']:,}<br>\n",
    "                <b>Sin Cubrir:</b> {row['POBLACION_SIN_CUBRIR']:,}<br>\n",
    "                <b>Cobertura:</b> {row['PORCENTAJE_COBERTURA']*100:.1f}%<br>\n",
    "                <b>PUDOs actuales:</b> {row['CANTIDAD_PUDOS_LOCALIDAD']}<br>\n",
    "                <hr>\n",
    "                <b style='color:{color}'>{tipo}</b>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            folium.CircleMarker(\n",
    "                location=[lat_mean, lon_mean],\n",
    "                radius=10,\n",
    "                color=color,\n",
    "                fill=True,\n",
    "                fillColor=color,\n",
    "                fillOpacity=0.7,\n",
    "                popup=folium.Popup(popup_html, max_width=250)\n",
    "            ).add_to(fg_oportunidades)\n",
    "\n",
    "    fg_oportunidades.add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# G. CAPA 5: ZONAS SOBRESERVIDAS (Para optimizar)\n",
    "# ==========================================\n",
    "\n",
    "print(\"Identificando zonas sobreservidas...\")\n",
    "\n",
    "df_sobreservido = df_map_poblado[\n",
    "    (df_map_poblado['pudos_en_manzana'] > 3) &\n",
    "    (df_map_poblado['pct_cobertura'] > 0.9)\n",
    " ]\n",
    "\n",
    "if len(df_sobreservido) > 0:\n",
    "    fg_sobreservido = folium.FeatureGroup(name='Zonas Sobreservidas (Optimizar)', show=False)\n",
    "    localidad_groups = df_sobreservido.groupby(['COMUNA', 'LOCALIDAD'])\n",
    "    count_added = 0\n",
    "    for (comuna, localidad), subset in localidad_groups:\n",
    "        if len(subset) > 3 and count_added < 40:\n",
    "            lat_mean = subset['lat'].mean()\n",
    "            lon_mean = subset['lon'].mean()\n",
    "            folium.CircleMarker(\n",
    "                location=[lat_mean, lon_mean],\n",
    "                radius=8,\n",
    "                color='blue',\n",
    "                fill=True,\n",
    "                fillColor='blue',\n",
    "                fillOpacity=0.5,\n",
    "                popup=f\"{localidad}<br>Comuna: {comuna}<br>Alta densidad de PUDOs\"\n",
    "            ).add_to(fg_sobreservido)\n",
    "            count_added += 1\n",
    "    fg_sobreservido.add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# H. AGREGAR CONTROLES Y LEYENDA\n",
    "# ==========================================\n",
    "\n",
    "print(\"Agregando controles...\")\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(mapa)\n",
    "\n",
    "# ==========================================\n",
    "# H.1. AGREGAR BARRA DE BÚSQUEDA\n",
    "# ==========================================\n",
    "\n",
    "print(\"Agregando barra de búsqueda...\")\n",
    "\n",
    "import json\n",
    "\n",
    "# Construir diccionario maestro de búsqueda\n",
    "search_dict = {}\n",
    "\n",
    "# 1. Comunas (desde Forecast si existe, o desde df_map)\n",
    "if 'df_forecast_geo' in locals() and not df_forecast_geo.empty:\n",
    "    for idx, row in df_forecast_geo.iterrows():\n",
    "        search_dict[row['comuna']] = [row['lat'], row['lon']]\n",
    "else:\n",
    "    # Fallback: centroids de Comuna desde df_map\n",
    "    c_centers = df_map.groupby('COMUNA')[['lat', 'lon']].mean().reset_index()\n",
    "    for _, row in c_centers.iterrows():\n",
    "        search_dict[row['COMUNA']] = [row['lat'], row['lon']]\n",
    "\n",
    "# 2. Localidades (Implementación de búsqueda por Comuna + Localidad)\n",
    "print(\"   Indexando Localidades (Comuna + Localidad) para el buscador...\")\n",
    "# Agrupar df_map por (Comuna, Localidad) para obtener centroide único\n",
    "loc_centers = df_map.groupby(['COMUNA', 'LOCALIDAD'])[['lat', 'lon']].mean().reset_index()\n",
    "\n",
    "for idx, row in loc_centers.iterrows():\n",
    "    # Crear etiqueta combinada\n",
    "    label = f\"{row['LOCALIDAD']} ({row['COMUNA']})\"\n",
    "    search_dict[label] = [row['lat'], row['lon']]\n",
    "\n",
    "print(f\"   Total de entradas en el buscador: {len(search_dict)}\")\n",
    "\n",
    "if search_dict:\n",
    "    # Javascript personalizado para la búsqueda\n",
    "    # Usamos 'comunas' como nombre de variable en JS para mantener estructura, pero contiene Localidades también.\n",
    "    \n",
    "    # Get map ID\n",
    "    map_id = mapa.get_name()\n",
    "    \n",
    "    search_html = f\"\"\"\n",
    "    <div id=\"search-box\" style=\"\n",
    "        position: fixed;\n",
    "        top: 10px;\n",
    "        left: 60px;\n",
    "        z-index: 1000;\n",
    "        background-color: white;\n",
    "        padding: 10px;\n",
    "        border-radius: 5px;\n",
    "        box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
    "        font-family: sans-serif;\n",
    "    \">\n",
    "        <input type=\"text\" id=\"comuna-search\" list=\"comunas-list\" \n",
    "               placeholder=\"Buscar Comuna o Localidad...\" \n",
    "               style=\"width: 250px; padding: 5px; border: 1px solid #ccc; border-radius: 3px;\">\n",
    "        <datalist id=\"comunas-list\">\n",
    "            {''.join([f'<option value=\"{k}\">' for k in search_dict.keys()])}\n",
    "        </datalist>\n",
    "        <button onclick=\"searchAction()\" style=\"\n",
    "            padding: 5px 10px;\n",
    "            background-color: #0066cc;\n",
    "            color: white;\n",
    "            border: none;\n",
    "            border-radius: 3px;\n",
    "            cursor: pointer;\n",
    "            margin-left: 5px;\n",
    "        \">Ir</button>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        var locations = {json.dumps(search_dict)};\n",
    "        \n",
    "        function searchAction() {{\n",
    "            var input = document.getElementById('comuna-search').value.trim();\n",
    "            \n",
    "            if (!input) {{\n",
    "                alert('Por favor ingrese un nombre.');\n",
    "                return;\n",
    "            }}\n",
    "            \n",
    "            var targetCoords = locations[input];\n",
    "            \n",
    "            // Si no hay match exacto, intentar búsqueda parcial (case-insensitive)\n",
    "            if (!targetCoords) {{\n",
    "                var lowerInput = input.toLowerCase();\n",
    "                for (var key in locations) {{\n",
    "                    if (key.toLowerCase() === lowerInput) {{\n",
    "                        targetCoords = locations[key];\n",
    "                        break;\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "            \n",
    "            if (targetCoords) {{\n",
    "                var mapObj = window['{map_id}'];\n",
    "                if (mapObj) {{\n",
    "                    mapObj.setView(targetCoords, 14); // Zoom más cercano para localidades\n",
    "                }}\n",
    "            }} else {{\n",
    "                alert('Lugar no encontrado en el índice.');\n",
    "            }}\n",
    "        }}\n",
    "        \n",
    "        document.getElementById('comuna-search').addEventListener('keypress', function(e) {{\n",
    "            if (e.key === 'Enter') {{\n",
    "                searchAction();\n",
    "            }}\n",
    "        }});\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    mapa.get_root().html.add_child(folium.Element(search_html))\n",
    "    print(\"   Barra de búsqueda agregada (Comunas y Localidades).\")\n",
    "\n",
    "# ==========================================\n",
    "# I. GUARDAR MAPA\n",
    "# ==========================================\n",
    "\n",
    "filename_mapa = 'Mapa_Cobertura_Nacional_Blue.html'\n",
    "mapa.save(filename_mapa)\n",
    "\n",
    "print(f\"\\n✅ Mapa interactivo generado: {filename_mapa}\")\n",
    "print(f\"   Tamaño aproximado del archivo: {len(heat_data_sin_cobertura):,} puntos de calor\")\n",
    "print(\"\\nInstrucciones: abra el HTML, use panel de capas y haga zoom para detalle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079944df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>esto_seq_cdg</th>\n",
       "      <th>ofcn_dsc</th>\n",
       "      <th>cmns_nmb</th>\n",
       "      <th>geol_latitud</th>\n",
       "      <th>geol_longitud</th>\n",
       "      <th>tipo_punto</th>\n",
       "      <th>apto_locker</th>\n",
       "      <th>tiene_locker</th>\n",
       "      <th>q dao avg mes</th>\n",
       "      <th>q dao max mes</th>\n",
       "      <th>avg_packages_daily</th>\n",
       "      <th>peak_packages_weekly</th>\n",
       "      <th>sobrecapacidad HOY - capacidad actual</th>\n",
       "      <th>sobrecapacidad fcst peak - capacidad proyectada</th>\n",
       "      <th>share del punto en la comuna</th>\n",
       "      <th>geometry</th>\n",
       "      <th>COMUNA_NORM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DROP OFF BX LIMITADA PRUEBA PROD</td>\n",
       "      <td>PUENTE ALTO</td>\n",
       "      <td>-33.564457</td>\n",
       "      <td>-70.545033</td>\n",
       "      <td>partner</td>\n",
       "      <td>si</td>\n",
       "      <td>no</td>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2%</td>\n",
       "      <td>POINT (-70.54503 -33.56446)</td>\n",
       "      <td>PUENTE ALTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Centro Drop Off Paseo Bulnes</td>\n",
       "      <td>SANTIAGO</td>\n",
       "      <td>-33.446105</td>\n",
       "      <td>-70.653481</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>POINT (-70.65348 -33.4461)</td>\n",
       "      <td>SANTIAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Punto Blue Express Cyber Don Francis</td>\n",
       "      <td>SANTIAGO</td>\n",
       "      <td>-33.446482</td>\n",
       "      <td>-70.645693</td>\n",
       "      <td>blue</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>30</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1%</td>\n",
       "      <td>POINT (-70.64569 -33.44648)</td>\n",
       "      <td>SANTIAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>Centro Drop Off Portugal</td>\n",
       "      <td>SANTIAGO</td>\n",
       "      <td>-33.463074</td>\n",
       "      <td>-70.631230</td>\n",
       "      <td>blue</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>26</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1%</td>\n",
       "      <td>POINT (-70.63123 -33.46307)</td>\n",
       "      <td>SANTIAGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Punto Blue Express Almacen Belorado</td>\n",
       "      <td>NUNOA</td>\n",
       "      <td>-33.450194</td>\n",
       "      <td>-70.620355</td>\n",
       "      <td>blue</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1%</td>\n",
       "      <td>POINT (-70.62035 -33.45019)</td>\n",
       "      <td>NUNOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>9995</td>\n",
       "      <td>Punto Blue Express Copec Pitrufquen</td>\n",
       "      <td>PITRUFQUEN</td>\n",
       "      <td>-38.983739</td>\n",
       "      <td>-72.640687</td>\n",
       "      <td>copec</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>280</td>\n",
       "      <td>337</td>\n",
       "      <td>13</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>91%</td>\n",
       "      <td>POINT (-72.64069 -38.98374)</td>\n",
       "      <td>PITRUFQUEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>9996</td>\n",
       "      <td>Punto Blue Express Copec Lanco</td>\n",
       "      <td>LANCO</td>\n",
       "      <td>-39.449859</td>\n",
       "      <td>-72.780135</td>\n",
       "      <td>copec</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18%</td>\n",
       "      <td>POINT (-72.78013 -39.44986)</td>\n",
       "      <td>LANCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>9997</td>\n",
       "      <td>Punto Blue Express Copec Nueva Imperial</td>\n",
       "      <td>NUEVA IMPERIAL</td>\n",
       "      <td>-38.748215</td>\n",
       "      <td>-72.951316</td>\n",
       "      <td>copec</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>471</td>\n",
       "      <td>503</td>\n",
       "      <td>21</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74%</td>\n",
       "      <td>POINT (-72.95132 -38.74822)</td>\n",
       "      <td>NUEVA IMPERIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>9998</td>\n",
       "      <td>Punto Blue Express Copec Gorbea</td>\n",
       "      <td>GORBEA</td>\n",
       "      <td>-39.098640</td>\n",
       "      <td>-72.672390</td>\n",
       "      <td>copec</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>254</td>\n",
       "      <td>298</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70%</td>\n",
       "      <td>POINT (-72.67239 -39.09864)</td>\n",
       "      <td>GORBEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>9999</td>\n",
       "      <td>Punto Blue Express Copec Malalhue</td>\n",
       "      <td>LANCO</td>\n",
       "      <td>-39.540730</td>\n",
       "      <td>-72.509380</td>\n",
       "      <td>copec</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>255</td>\n",
       "      <td>286</td>\n",
       "      <td>12</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63%</td>\n",
       "      <td>POINT (-72.50938 -39.54073)</td>\n",
       "      <td>LANCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3424 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      esto_seq_cdg                                 ofcn_dsc        cmns_nmb  \\\n",
       "0                1         DROP OFF BX LIMITADA PRUEBA PROD     PUENTE ALTO   \n",
       "1                2             Centro Drop Off Paseo Bulnes        SANTIAGO   \n",
       "2               28     Punto Blue Express Cyber Don Francis        SANTIAGO   \n",
       "3               29                 Centro Drop Off Portugal        SANTIAGO   \n",
       "4               33      Punto Blue Express Almacen Belorado           NUNOA   \n",
       "...            ...                                      ...             ...   \n",
       "3419          9995      Punto Blue Express Copec Pitrufquen      PITRUFQUEN   \n",
       "3420          9996           Punto Blue Express Copec Lanco           LANCO   \n",
       "3421          9997  Punto Blue Express Copec Nueva Imperial  NUEVA IMPERIAL   \n",
       "3422          9998          Punto Blue Express Copec Gorbea          GORBEA   \n",
       "3423          9999        Punto Blue Express Copec Malalhue           LANCO   \n",
       "\n",
       "      geol_latitud  geol_longitud tipo_punto apto_locker tiene_locker  \\\n",
       "0       -33.564457     -70.545033    partner          si           no   \n",
       "1       -33.446105     -70.653481          -           -            -   \n",
       "2       -33.446482     -70.645693       blue          no           no   \n",
       "3       -33.463074     -70.631230       blue          no           no   \n",
       "4       -33.450194     -70.620355       blue          no           no   \n",
       "...            ...            ...        ...         ...          ...   \n",
       "3419    -38.983739     -72.640687      copec          si           si   \n",
       "3420    -39.449859     -72.780135      copec          si           si   \n",
       "3421    -38.748215     -72.951316      copec          si           si   \n",
       "3422    -39.098640     -72.672390      copec          si           si   \n",
       "3423    -39.540730     -72.509380      copec          si           si   \n",
       "\n",
       "     q dao avg mes q dao max mes avg_packages_daily peak_packages_weekly  \\\n",
       "0               37            54                  4                   38   \n",
       "1                -             -                  -                    -   \n",
       "2               30            51                  2                   35   \n",
       "3               26            47                  2                   16   \n",
       "4               18            27                  2                   12   \n",
       "...            ...           ...                ...                  ...   \n",
       "3419           280           337                 13                  138   \n",
       "3420            71            88                  4                   28   \n",
       "3421           471           503                 21                  166   \n",
       "3422           254           298                 11                  101   \n",
       "3423           255           286                 12                   94   \n",
       "\n",
       "     sobrecapacidad HOY - capacidad actual  \\\n",
       "0                                        1   \n",
       "1                                        -   \n",
       "2                                        1   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "3419                                     1   \n",
       "3420                                     0   \n",
       "3421                                     0   \n",
       "3422                                     0   \n",
       "3423                                     0   \n",
       "\n",
       "     sobrecapacidad fcst peak - capacidad proyectada  \\\n",
       "0                                                  1   \n",
       "1                                                  -   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "3419                                               0   \n",
       "3420                                               0   \n",
       "3421                                               1   \n",
       "3422                                               1   \n",
       "3423                                               1   \n",
       "\n",
       "     share del punto en la comuna                     geometry     COMUNA_NORM  \n",
       "0                              2%  POINT (-70.54503 -33.56446)     PUENTE ALTO  \n",
       "1                               -   POINT (-70.65348 -33.4461)        SANTIAGO  \n",
       "2                              1%  POINT (-70.64569 -33.44648)        SANTIAGO  \n",
       "3                              1%  POINT (-70.63123 -33.46307)        SANTIAGO  \n",
       "4                              1%  POINT (-70.62035 -33.45019)           NUNOA  \n",
       "...                           ...                          ...             ...  \n",
       "3419                          91%  POINT (-72.64069 -38.98374)      PITRUFQUEN  \n",
       "3420                          18%  POINT (-72.78013 -39.44986)           LANCO  \n",
       "3421                          74%  POINT (-72.95132 -38.74822)  NUEVA IMPERIAL  \n",
       "3422                          70%  POINT (-72.67239 -39.09864)          GORBEA  \n",
       "3423                          63%  POINT (-72.50938 -39.54073)           LANCO  \n",
       "\n",
       "[3424 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_PUDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b9314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
